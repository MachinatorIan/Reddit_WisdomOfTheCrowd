{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import praw\n",
    "from praw.models import MoreComments\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from math import ceil\n",
    "from nltk.util import pad_sequence\n",
    "from nltk.util import bigrams\n",
    "from nltk.util import ngrams\n",
    "from nltk.util import everygrams\n",
    "\n",
    "import nltk.data\n",
    "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from nltk.lm.preprocessing import pad_both_ends\n",
    "from nltk.lm.preprocessing import flatten\n",
    "\n",
    "from math import floor\n",
    "import copy\n",
    "\n",
    "from submission_corpus import SubmissionCorpus\n",
    "from ngram_generator import NgramCommentGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bc'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'abc'\n",
    "s.replace('a','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id = '71ZX5Cupn2Ohpg'\n",
    "client_secret = 'nzCz5_WlQM4LbJxX-t_3m-tPgZw'\n",
    "\n",
    "reddit = praw.Reddit(user_agent='Comment Extraction',client_id=client_id, client_secret=client_secret)\n",
    "subreddit = reddit.subreddit('AmITheAsshole')\n",
    "\n",
    "judgement_categories = ['YTA', 'NTA', 'ESH', 'NAH', 'INFO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SubmissionCorpus(reddit.submission(id='dv9ogm'), bfs_depth=1, judgement_categories=judgement_categories, judgement_weight='none')\n",
    "cc = sc.get_commentCorpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncg = NgramCommentGenerator(cc, N=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<c> <s> YTA . </s> <s> I think your desire for a child does not outweigh your SIL 's desire to `` keep it in the family . </s> <s> I get that you can ’ t get pregnant yourself but can you at least think about the emotional toll it would be to get pregnant with your brother ’ s child , carry it to term , GO THROUGH BIRTH , and then no matter if your feelings change and transform the child YOU carried is then taken from you to be raised by your brother and sister in law feels or reacted are unnecessary . </s> <s> I puked multiple times a day every day for seven months with nothing being wrong during my very wanted pregnancy . </s> <s> A get reasonable boundary to have when she 's currently upset . </s> <s> To ask this of your sister just because he wants to keep it “ in the blood ” is fucking creepy and crosses so many boundaries . </s> </c>\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncg.generate_comment('YTA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Submission_Corpus:\n",
    "    def __init__(self, submission, bfs_depth=2, judgement_categories=None, judgement_weight='upvotes'):\n",
    "        self.comment_meta = []\n",
    "        self.judgement_categories = judgement_categories\n",
    "        self.judgement_weight = judgement_weight\n",
    "        self.judgements = {}\n",
    "        for category in self.judgement_categories:\n",
    "            self.judgements[category] = []\n",
    "\n",
    "        self.submission = submission\n",
    "        self.original_post = submission.selftext\n",
    "        self.comment_forrest = self.submission.comments\n",
    "        self.comment_bfs(bfs_depth=bfs_depth)       \n",
    "        \n",
    "    def comment_bfs(self, bfs_depth=0):\n",
    "        # Initialize queue to hold comment sub trees during BFS.\n",
    "        bfs_queue = []\n",
    "        \n",
    "        # Populate queue with first level of comments.\n",
    "        for comment in self.comment_forrest:\n",
    "            bfs_queue.append(comment)\n",
    "            \n",
    "        current_level_size = len(bfs_queue)\n",
    "        next_level_size = 0\n",
    "        level_count = 0\n",
    "        \n",
    "        while (len(bfs_queue) > 0) and (level_count < bfs_depth):\n",
    "            comment = bfs_queue.pop(0)\n",
    "            current_level_size -= 1\n",
    "            next_level_size += 1\n",
    "            \n",
    "            comment_features = None\n",
    "            try:\n",
    "                comment_features = self.extract_comment(comment)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            if comment_features is not None:\n",
    "                self.comment_meta.append(comment_features)\n",
    "                for reply in comment.replies:\n",
    "                    bfs_queue.append(reply)\n",
    "            \n",
    "            if current_level_size == 0:\n",
    "                current_level_size = next_level_size\n",
    "                level_count += 1\n",
    "            \n",
    "    def extract_comment(self, comment, judgement_extraction_method='prefix', judgement_weighting='upvotes'):\n",
    "        judgement = self.extract_judgement(comment.body, extraction_method=judgement_extraction_method)\n",
    "        score = comment.score if judgement_weighting=='upvotes' else 1\n",
    "        self.judgements[judgement].append(score)\n",
    "        body = self.tokenize_comment(comment.body)\n",
    "        comment_features = {\n",
    "            'id' : comment.id,\n",
    "            'author': comment.author,\n",
    "            'body': body,\n",
    "            'score' : score,\n",
    "            'judgement': judgement\n",
    "        }\n",
    "        return(comment_features)\n",
    "    \n",
    "    def extract_judgement(self, txt, extraction_method='prefix'):\n",
    "        if extraction_method == 'prefix':\n",
    "            for category in self.judgement_categories:\n",
    "                if txt[:len(category)] == category:\n",
    "                    return(category)\n",
    "    \n",
    "    def summarize_judgement(self):\n",
    "        total_judgements = sum([sum(count) for count in self.judgements.values()])\n",
    "        judgement_summary = [(category, sum(count)/total_judgements) for category, count in self.judgements.items()]\n",
    "        return(judgement_summary)\n",
    "    \n",
    "    def get_judgement_summary(self):\n",
    "        return(self.judgement_summary)\n",
    "    \n",
    "    def tokenize_sentence(self, sent):\n",
    "        try:\n",
    "            tokenized_sent = word_tokenize(sent)\n",
    "        except:\n",
    "            tokenized_sent = []\n",
    "        tokenized_sent.insert(0, '<s>')\n",
    "        tokenized_sent.append('</s>')\n",
    "        return(tokenized_sent)\n",
    "    \n",
    "    def tokenize_comment(self, comment_txt):\n",
    "        sentences = sent_detector.tokenize(comment_txt.strip())\n",
    "        tokenized_sentences = [self.tokenize_sentence(sent) for sent in sentences]\n",
    "        tokenized_comment = ['<c>']\n",
    "        for sent in tokenized_sentences:\n",
    "            tokenized_comment += sent\n",
    "        tokenized_comment += ['</c>']\n",
    "        return(tokenized_comment)\n",
    "        \n",
    "    def get_commentCorpus(self):\n",
    "        comments_by_category = {}\n",
    "        for category in self.judgement_categories:\n",
    "            comments_by_category[category] = []\n",
    "        \n",
    "        \n",
    "        for comment in self.comment_meta:\n",
    "            if self.judgement_weight == 'upvotes':\n",
    "                for i in range(max(5,floor(comment['score']/50))):\n",
    "                    comments_by_category[comment['judgement']].append(comment['body'])\n",
    "                    \n",
    "            else:\n",
    "                comments_by_category[comment['judgement']].append(comment['body'])            \n",
    "                \n",
    "        return(comments_by_category)\n",
    "    \n",
    "    def get_simpleWeightedCorpus(self):\n",
    "        comments_by_category = {}\n",
    "        for category in self.judgement_categories:\n",
    "            comments_by_category[category] = []\n",
    "        \n",
    "        for comment in self.comment_meta:\n",
    "            comments_by_category[comment['judgement']].append((comment['score'], comment['body']))          \n",
    "        \n",
    "        return(comments_by_category)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SC = Submission_Corpus(reddit.submission(id='dv9ogm'), bfs_depth=1, judgement_categories=judgement_categories, judgement_weight='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('YTA', 0.9961707901927617),\n",
       " ('NTA', 0.0),\n",
       " ('ESH', 0.0),\n",
       " ('NAH', 0.0),\n",
       " ('INFO', 0.003829209807238322)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SC.summarize_judgement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = SC.get_commentCorpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "swcc = SC.get_simpleWeightedCorpus()\n",
    "f = open('dv9ogm_corpus.txt', 'w')\n",
    "f.write(str(swcc))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<c>', '<s>', 'YTA', '.', '</s>', '<s>', 'I', '’', 'm', 'trying', 'to', 'say', 'that', 'as', 'kindly', 'as', 'possible', 'but', 'why', 'would', 'you', 'think', 'someone', 'who', 'is', 'adamantly', 'against', 'having', 'children', 'would', 'want', 'to', 'carry', 'yours', '?', '</s>', '<s>', 'If', 'your', 'husband', 'is', 'that', 'close', 'to', 'his', 'sister', ',', 'I', 'would', 'have', 'thought', 'that', 'he', 'would', 'know', 'better', 'than', 'to', 'make', 'such', 'a', 'tone', 'deaf', 'request', '.', '</s>', '<s>', 'Also', ',', 'it', 'may', 'be', 'unrelated', ',', 'but', 'the', '“', 'important', 'to', 'keep', 'this', 'surrogacy', 'confined', 'to', 'his', 'blood', '”', 'bit', 'makes', 'me', 'roll', 'my', 'eyes', 'so', 'hard', '.', '</s>', '<s>', 'Your', 'parents', 'are', 'of', 'course', 'only', 'going', 'to', 'see', 'this', 'from', 'your', 'point', 'of', 'view', 'so', 'their', 'opinions', 'on', 'how', 'your', 'sister', 'in', 'law', 'feels', 'or', 'reacted', 'are', 'unnecessary', '.', '</s>', '<s>', 'At', 'the', 'end', 'of', 'the', 'day', ',', 'you', 'guys', 'should', 'have', 'considered', 'your', 'sister', 'in', 'law', '’', 's', 'feelings', 'way', 'more', 'than', 'you', 'did', '.', '</s>', '<s>', 'You', 'asked', 'a', 'massive', 'favor', 'of', 'someone', 'who', 'has', 'made', 'clear', 'they', 'want', 'nothing', 'to', 'do', 'with', 'children', ',', 'which', 'probably', 'tells', 'her', 'you', 'don', '’', 't', 'care', 'at', 'all', 'about', 'her', 'or', 'the', 'things', 'she', 'wants', 'for', 'her', 'life', ',', 'you', 'just', 'saw', 'her', 'as', 'a', 'potential', 'womb', '.', '</s>', '<s>', 'You', '’', 'd', 'probably', 'do', 'well', 'to', 'hold', 'off', 'on', 'contacting', 'her', 'until', 'she', '’', 's', 'ready', '.', '</s>', '</c>']\n"
     ]
    }
   ],
   "source": [
    "print(cc['YTA'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<c>', '<s>', 'YTA')\n",
      "('<s>', 'YTA', '.')\n",
      "('YTA', '.', '</s>')\n",
      "('.', '</s>', '<s>')\n",
      "('</s>', '<s>', 'I')\n",
      "('<s>', 'I', '’')\n",
      "('I', '’', 'm')\n",
      "('’', 'm', 'trying')\n",
      "('m', 'trying', 'to')\n",
      "('trying', 'to', 'say')\n",
      "('to', 'say', 'that')\n",
      "('say', 'that', 'as')\n",
      "('that', 'as', 'kindly')\n",
      "('as', 'kindly', 'as')\n",
      "('kindly', 'as', 'possible')\n",
      "('as', 'possible', 'but')\n",
      "('possible', 'but', 'why')\n",
      "('but', 'why', 'would')\n",
      "('why', 'would', 'you')\n",
      "('would', 'you', 'think')\n",
      "('you', 'think', 'someone')\n",
      "('think', 'someone', 'who')\n",
      "('someone', 'who', 'is')\n",
      "('who', 'is', 'adamantly')\n",
      "('is', 'adamantly', 'against')\n",
      "('adamantly', 'against', 'having')\n",
      "('against', 'having', 'children')\n",
      "('having', 'children', 'would')\n",
      "('children', 'would', 'want')\n",
      "('would', 'want', 'to')\n",
      "('want', 'to', 'carry')\n",
      "('to', 'carry', 'yours')\n",
      "('carry', 'yours', '?')\n",
      "('yours', '?', '</s>')\n",
      "('?', '</s>', '<s>')\n",
      "('</s>', '<s>', 'If')\n",
      "('<s>', 'If', 'your')\n",
      "('If', 'your', 'husband')\n",
      "('your', 'husband', 'is')\n",
      "('husband', 'is', 'that')\n",
      "('is', 'that', 'close')\n",
      "('that', 'close', 'to')\n",
      "('close', 'to', 'his')\n",
      "('to', 'his', 'sister')\n",
      "('his', 'sister', ',')\n",
      "('sister', ',', 'I')\n",
      "(',', 'I', 'would')\n",
      "('I', 'would', 'have')\n",
      "('would', 'have', 'thought')\n",
      "('have', 'thought', 'that')\n",
      "('thought', 'that', 'he')\n",
      "('that', 'he', 'would')\n",
      "('he', 'would', 'know')\n",
      "('would', 'know', 'better')\n",
      "('know', 'better', 'than')\n",
      "('better', 'than', 'to')\n",
      "('than', 'to', 'make')\n",
      "('to', 'make', 'such')\n",
      "('make', 'such', 'a')\n",
      "('such', 'a', 'tone')\n",
      "('a', 'tone', 'deaf')\n",
      "('tone', 'deaf', 'request')\n",
      "('deaf', 'request', '.')\n",
      "('request', '.', '</s>')\n",
      "('.', '</s>', '<s>')\n",
      "('</s>', '<s>', 'Also')\n",
      "('<s>', 'Also', ',')\n",
      "('Also', ',', 'it')\n",
      "(',', 'it', 'may')\n",
      "('it', 'may', 'be')\n",
      "('may', 'be', 'unrelated')\n",
      "('be', 'unrelated', ',')\n",
      "('unrelated', ',', 'but')\n",
      "(',', 'but', 'the')\n",
      "('but', 'the', '“')\n",
      "('the', '“', 'important')\n",
      "('“', 'important', 'to')\n",
      "('important', 'to', 'keep')\n",
      "('to', 'keep', 'this')\n",
      "('keep', 'this', 'surrogacy')\n",
      "('this', 'surrogacy', 'confined')\n",
      "('surrogacy', 'confined', 'to')\n",
      "('confined', 'to', 'his')\n",
      "('to', 'his', 'blood')\n",
      "('his', 'blood', '”')\n",
      "('blood', '”', 'bit')\n",
      "('”', 'bit', 'makes')\n",
      "('bit', 'makes', 'me')\n",
      "('makes', 'me', 'roll')\n",
      "('me', 'roll', 'my')\n",
      "('roll', 'my', 'eyes')\n",
      "('my', 'eyes', 'so')\n",
      "('eyes', 'so', 'hard')\n",
      "('so', 'hard', '.')\n",
      "('hard', '.', '</s>')\n",
      "('.', '</s>', '<s>')\n",
      "('</s>', '<s>', 'Your')\n",
      "('<s>', 'Your', 'parents')\n",
      "('Your', 'parents', 'are')\n",
      "('parents', 'are', 'of')\n",
      "('are', 'of', 'course')\n",
      "('of', 'course', 'only')\n",
      "('course', 'only', 'going')\n",
      "('only', 'going', 'to')\n",
      "('going', 'to', 'see')\n",
      "('to', 'see', 'this')\n",
      "('see', 'this', 'from')\n",
      "('this', 'from', 'your')\n",
      "('from', 'your', 'point')\n",
      "('your', 'point', 'of')\n",
      "('point', 'of', 'view')\n",
      "('of', 'view', 'so')\n",
      "('view', 'so', 'their')\n",
      "('so', 'their', 'opinions')\n",
      "('their', 'opinions', 'on')\n",
      "('opinions', 'on', 'how')\n",
      "('on', 'how', 'your')\n",
      "('how', 'your', 'sister')\n",
      "('your', 'sister', 'in')\n",
      "('sister', 'in', 'law')\n",
      "('in', 'law', 'feels')\n",
      "('law', 'feels', 'or')\n",
      "('feels', 'or', 'reacted')\n",
      "('or', 'reacted', 'are')\n",
      "('reacted', 'are', 'unnecessary')\n",
      "('are', 'unnecessary', '.')\n",
      "('unnecessary', '.', '</s>')\n",
      "('.', '</s>', '<s>')\n",
      "('</s>', '<s>', 'At')\n",
      "('<s>', 'At', 'the')\n",
      "('At', 'the', 'end')\n",
      "('the', 'end', 'of')\n",
      "('end', 'of', 'the')\n",
      "('of', 'the', 'day')\n",
      "('the', 'day', ',')\n",
      "('day', ',', 'you')\n",
      "(',', 'you', 'guys')\n",
      "('you', 'guys', 'should')\n",
      "('guys', 'should', 'have')\n",
      "('should', 'have', 'considered')\n",
      "('have', 'considered', 'your')\n",
      "('considered', 'your', 'sister')\n",
      "('your', 'sister', 'in')\n",
      "('sister', 'in', 'law')\n",
      "('in', 'law', '’')\n",
      "('law', '’', 's')\n",
      "('’', 's', 'feelings')\n",
      "('s', 'feelings', 'way')\n",
      "('feelings', 'way', 'more')\n",
      "('way', 'more', 'than')\n",
      "('more', 'than', 'you')\n",
      "('than', 'you', 'did')\n",
      "('you', 'did', '.')\n",
      "('did', '.', '</s>')\n",
      "('.', '</s>', '<s>')\n",
      "('</s>', '<s>', 'You')\n",
      "('<s>', 'You', 'asked')\n",
      "('You', 'asked', 'a')\n",
      "('asked', 'a', 'massive')\n",
      "('a', 'massive', 'favor')\n",
      "('massive', 'favor', 'of')\n",
      "('favor', 'of', 'someone')\n",
      "('of', 'someone', 'who')\n",
      "('someone', 'who', 'has')\n",
      "('who', 'has', 'made')\n",
      "('has', 'made', 'clear')\n",
      "('made', 'clear', 'they')\n",
      "('clear', 'they', 'want')\n",
      "('they', 'want', 'nothing')\n",
      "('want', 'nothing', 'to')\n",
      "('nothing', 'to', 'do')\n",
      "('to', 'do', 'with')\n",
      "('do', 'with', 'children')\n",
      "('with', 'children', ',')\n",
      "('children', ',', 'which')\n",
      "(',', 'which', 'probably')\n",
      "('which', 'probably', 'tells')\n",
      "('probably', 'tells', 'her')\n",
      "('tells', 'her', 'you')\n",
      "('her', 'you', 'don')\n",
      "('you', 'don', '’')\n",
      "('don', '’', 't')\n",
      "('’', 't', 'care')\n",
      "('t', 'care', 'at')\n",
      "('care', 'at', 'all')\n",
      "('at', 'all', 'about')\n",
      "('all', 'about', 'her')\n",
      "('about', 'her', 'or')\n",
      "('her', 'or', 'the')\n",
      "('or', 'the', 'things')\n",
      "('the', 'things', 'she')\n",
      "('things', 'she', 'wants')\n",
      "('she', 'wants', 'for')\n",
      "('wants', 'for', 'her')\n",
      "('for', 'her', 'life')\n",
      "('her', 'life', ',')\n",
      "('life', ',', 'you')\n",
      "(',', 'you', 'just')\n",
      "('you', 'just', 'saw')\n",
      "('just', 'saw', 'her')\n",
      "('saw', 'her', 'as')\n",
      "('her', 'as', 'a')\n",
      "('as', 'a', 'potential')\n",
      "('a', 'potential', 'womb')\n",
      "('potential', 'womb', '.')\n",
      "('womb', '.', '</s>')\n",
      "('.', '</s>', '<s>')\n",
      "('</s>', '<s>', 'You')\n",
      "('<s>', 'You', '’')\n",
      "('You', '’', 'd')\n",
      "('’', 'd', 'probably')\n",
      "('d', 'probably', 'do')\n",
      "('probably', 'do', 'well')\n",
      "('do', 'well', 'to')\n",
      "('well', 'to', 'hold')\n",
      "('to', 'hold', 'off')\n",
      "('hold', 'off', 'on')\n",
      "('off', 'on', 'contacting')\n",
      "('on', 'contacting', 'her')\n",
      "('contacting', 'her', 'until')\n",
      "('her', 'until', 'she')\n",
      "('until', 'she', '’')\n",
      "('she', '’', 's')\n",
      "('’', 's', 'ready')\n",
      "('s', 'ready', '.')\n",
      "('ready', '.', '</s>')\n",
      "('.', '</s>', '</c>')\n"
     ]
    }
   ],
   "source": [
    "for i in ngrams(cc['YTA'][0],3):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ngram_corpus(corpus, N=3):\n",
    "    ngram_tups_list = list(ngrams(corpus, N))\n",
    "    ngram_corpus = []\n",
    "    for gi in ngram_tups_list:\n",
    "        if not gi[0:N-1] in [x[0] for x in ngram_corpus]:\n",
    "            next_word_dict = {}\n",
    "            \n",
    "            for gj in ngram_tups_list:\n",
    "                if gj[0:N-1] == gi[0:N-1]:\n",
    "                    if gj[N-1] in next_word_dict.keys():\n",
    "                        next_word_dict[gj[N-1]] += 1\n",
    "                    else:\n",
    "                        next_word_dict[gj[N-1]] = 1\n",
    "            gi_count = sum(next_word_dict.values())\n",
    "            next_word_prob_tups = tuple([(key, value/gi_count) for key, value in next_word_dict.items()])\n",
    "            ngram_corpus.append((gi[0:N-1], gi_count, next_word_prob_tups))\n",
    "    return(ngram_corpus)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_comment_corpus = []\n",
    "for comment in cc['YTA']:\n",
    "    for token in comment:\n",
    "        flat_comment_corpus.append(token)\n",
    "        \n",
    "ngram_corpus = make_ngram_corpus(flat_comment_corpus,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('<c>', '<s>'), 24, (('YTA', 1.0),)),\n",
       " (('<s>', 'YTA'),\n",
       "  24,\n",
       "  (('.', 0.625),\n",
       "   ('Honestly', 0.041666666666666664),\n",
       "   ('for', 0.041666666666666664),\n",
       "   ('...', 0.041666666666666664),\n",
       "   ('-', 0.041666666666666664),\n",
       "   ('Why', 0.041666666666666664),\n",
       "   (',', 0.08333333333333333),\n",
       "   ('You', 0.041666666666666664),\n",
       "   ('jesus', 0.041666666666666664))),\n",
       " (('YTA', '.'), 15, (('</s>', 1.0),)),\n",
       " (('.', '</s>'),\n",
       "  143,\n",
       "  (('<s>', 0.8741258741258742), ('</c>', 0.1258741258741259))),\n",
       " (('</s>', '<s>'),\n",
       "  156,\n",
       "  (('I', 0.11538461538461539),\n",
       "   ('If', 0.03205128205128205),\n",
       "   ('Also', 0.019230769230769232),\n",
       "   ('Your', 0.03205128205128205),\n",
       "   ('At', 0.00641025641025641),\n",
       "   ('You', 0.14743589743589744),\n",
       "   ('It', 0.04487179487179487),\n",
       "   ('Edit', 0.01282051282051282),\n",
       "   ('And', 0.07051282051282051),\n",
       "   ('What', 0.05128205128205128),\n",
       "   ('Did', 0.00641025641025641),\n",
       "   ('Yes', 0.00641025641025641),\n",
       "   ('How', 0.02564102564102564),\n",
       "   ('Is', 0.00641025641025641),\n",
       "   ('Surrogacy', 0.00641025641025641),\n",
       "   ('Being', 0.00641025641025641),\n",
       "   (')', 0.00641025641025641),\n",
       "   ('She', 0.04487179487179487),\n",
       "   ('Maybe', 0.00641025641025641),\n",
       "   ('The', 0.019230769230769232),\n",
       "   ('For', 0.00641025641025641),\n",
       "   ('There', 0.038461538461538464),\n",
       "   ('Oh', 0.00641025641025641),\n",
       "   ('Do', 0.01282051282051282),\n",
       "   ('A', 0.019230769230769232),\n",
       "   ('Despite', 0.00641025641025641),\n",
       "   ('However', 0.00641025641025641),\n",
       "   ('First', 0.00641025641025641),\n",
       "   ('His', 0.00641025641025641),\n",
       "   ('Thinking', 0.00641025641025641),\n",
       "   ('Fucking', 0.00641025641025641),\n",
       "   ('So', 0.00641025641025641),\n",
       "   ('Then', 0.00641025641025641),\n",
       "   ('Mine', 0.00641025641025641),\n",
       "   (\"Y'all\", 0.00641025641025641),\n",
       "   ('As', 0.00641025641025641),\n",
       "   ('Someone', 0.00641025641025641),\n",
       "   ('That', 0.01282051282051282),\n",
       "   ('Why', 0.01282051282051282),\n",
       "   ('Wait', 0.00641025641025641),\n",
       "   ('Not', 0.00641025641025641),\n",
       "   ('No', 0.01282051282051282),\n",
       "   ('Just', 0.01282051282051282),\n",
       "   ('``', 0.00641025641025641),\n",
       "   ('PS', 0.00641025641025641),\n",
       "   ('Jesus', 0.00641025641025641),\n",
       "   ('Because', 0.00641025641025641),\n",
       "   ('(', 0.00641025641025641),\n",
       "   ('Which', 0.00641025641025641),\n",
       "   ('Think', 0.00641025641025641),\n",
       "   ('Good', 0.00641025641025641),\n",
       "   ('Many', 0.00641025641025641),\n",
       "   ('One', 0.00641025641025641),\n",
       "   ('Asking', 0.019230769230769232),\n",
       "   ('Childbirth', 0.00641025641025641),\n",
       "   ('To', 0.00641025641025641),\n",
       "   ('Man', 0.00641025641025641),\n",
       "   ('My', 0.00641025641025641))),\n",
       " (('<s>', 'I'),\n",
       "  18,\n",
       "  (('’', 0.1111111111111111),\n",
       "   ('get', 0.05555555555555555),\n",
       "   ('understand', 0.05555555555555555),\n",
       "   ('hope', 0.05555555555555555),\n",
       "   ('think', 0.16666666666666666),\n",
       "   (\"'m\", 0.1111111111111111),\n",
       "   (\"'d\", 0.05555555555555555),\n",
       "   ('do', 0.05555555555555555),\n",
       "   ('know', 0.05555555555555555),\n",
       "   ('see', 0.05555555555555555),\n",
       "   ('puked', 0.05555555555555555),\n",
       "   ('and', 0.05555555555555555),\n",
       "   ('would', 0.05555555555555555),\n",
       "   ('mean', 0.05555555555555555))),\n",
       " (('I', '’'), 5, (('m', 0.8), ('ve', 0.2))),\n",
       " (('’', 'm'),\n",
       "  4,\n",
       "  (('trying', 0.25), ('quite', 0.25), ('a', 0.25), ('not', 0.25))),\n",
       " (('m', 'trying'), 1, (('to', 1.0),)),\n",
       " (('trying', 'to'),\n",
       "  4,\n",
       "  (('say', 0.25), ('create', 0.25), ('force', 0.25), ('turn', 0.25))),\n",
       " (('to', 'say'), 2, (('that', 0.5), ('it', 0.5))),\n",
       " (('say', 'that'), 1, (('as', 1.0),)),\n",
       " (('that', 'as'), 1, (('kindly', 1.0),)),\n",
       " (('as', 'kindly'), 1, (('as', 1.0),)),\n",
       " (('kindly', 'as'), 1, (('possible', 1.0),)),\n",
       " (('as', 'possible'), 1, (('but', 1.0),)),\n",
       " (('possible', 'but'), 1, (('why', 1.0),)),\n",
       " (('but', 'why'), 1, (('would', 1.0),)),\n",
       " (('why', 'would'), 2, (('you', 0.5), (\"n't\", 0.5))),\n",
       " (('would', 'you'), 2, (('think', 0.5), ('handle', 0.5))),\n",
       " (('you', 'think'), 2, (('someone', 0.5), ('was', 0.5))),\n",
       " (('think', 'someone'), 1, (('who', 1.0),)),\n",
       " (('someone', 'who'),\n",
       "  6,\n",
       "  (('is', 0.5),\n",
       "   ('has', 0.16666666666666666),\n",
       "   ('would', 0.16666666666666666),\n",
       "   ('already', 0.16666666666666666))),\n",
       " (('who', 'is'),\n",
       "  4,\n",
       "  (('adamantly', 0.25), ('very', 0.25), (\"n't\", 0.25), ('vocally', 0.25))),\n",
       " (('is', 'adamantly'), 1, (('against', 1.0),)),\n",
       " (('adamantly', 'against'), 1, (('having', 1.0),)),\n",
       " (('against', 'having'), 2, (('children', 1.0),)),\n",
       " (('having', 'children'),\n",
       "  6,\n",
       "  (('would', 0.16666666666666666),\n",
       "   ('for', 0.16666666666666666),\n",
       "   ('.', 0.16666666666666666),\n",
       "   ('of', 0.16666666666666666),\n",
       "   ('makes', 0.16666666666666666),\n",
       "   ('in', 0.16666666666666666))),\n",
       " (('children', 'would'), 1, (('want', 1.0),)),\n",
       " (('would', 'want'), 2, (('to', 1.0),)),\n",
       " (('want', 'to'),\n",
       "  7,\n",
       "  (('carry', 0.2857142857142857),\n",
       "   ('submit', 0.14285714285714285),\n",
       "   ('abort', 0.14285714285714285),\n",
       "   ('be', 0.2857142857142857),\n",
       "   ('talk', 0.14285714285714285))),\n",
       " (('to', 'carry'),\n",
       "  5,\n",
       "  (('yours', 0.2), ('your', 0.2), ('and', 0.4), ('my', 0.2))),\n",
       " (('carry', 'yours'), 1, (('?', 1.0),)),\n",
       " (('yours', '?'), 1, (('</s>', 1.0),)),\n",
       " (('?', '</s>'),\n",
       "  27,\n",
       "  (('<s>', 0.9259259259259259), ('</c>', 0.07407407407407407))),\n",
       " (('<s>', 'If'), 5, (('your', 0.2), ('she', 0.2), ('you', 0.6))),\n",
       " (('If', 'your'), 1, (('husband', 1.0),)),\n",
       " (('your', 'husband'),\n",
       "  8,\n",
       "  (('is', 0.125),\n",
       "   (\"'s\", 0.375),\n",
       "   ('to', 0.125),\n",
       "   ('want', 0.125),\n",
       "   ('’', 0.125),\n",
       "   ('goes', 0.125))),\n",
       " (('husband', 'is'), 1, (('that', 1.0),)),\n",
       " (('is', 'that'), 2, (('close', 0.5), ('more', 0.5))),\n",
       " (('that', 'close'), 1, (('to', 1.0),)),\n",
       " (('close', 'to'), 1, (('his', 1.0),)),\n",
       " (('to', 'his'), 2, (('sister', 0.5), ('blood', 0.5))),\n",
       " (('his', 'sister'), 2, ((',', 0.5), ('is', 0.5))),\n",
       " (('sister', ','), 1, (('I', 1.0),)),\n",
       " ((',', 'I'),\n",
       "  6,\n",
       "  (('would', 0.16666666666666666),\n",
       "   ('am', 0.16666666666666666),\n",
       "   ('do', 0.16666666666666666),\n",
       "   ('physically', 0.16666666666666666),\n",
       "   ('also', 0.16666666666666666),\n",
       "   ('dunno', 0.16666666666666666))),\n",
       " (('I', 'would'),\n",
       "  3,\n",
       "  (('have', 0.3333333333333333),\n",
       "   ('want', 0.3333333333333333),\n",
       "   ('find', 0.3333333333333333))),\n",
       " (('would', 'have'), 1, (('thought', 1.0),)),\n",
       " (('have', 'thought'), 1, (('that', 1.0),)),\n",
       " (('thought', 'that'), 2, (('he', 0.5), ('she', 0.5))),\n",
       " (('that', 'he'), 1, (('would', 1.0),)),\n",
       " (('he', 'would'), 1, (('know', 1.0),)),\n",
       " (('would', 'know'), 1, (('better', 1.0),)),\n",
       " (('know', 'better'), 1, (('than', 1.0),)),\n",
       " (('better', 'than'), 1, (('to', 1.0),)),\n",
       " (('than', 'to'), 1, (('make', 1.0),)),\n",
       " (('to', 'make'), 1, (('such', 1.0),)),\n",
       " (('make', 'such'), 1, (('a', 1.0),)),\n",
       " (('such', 'a'), 1, (('tone', 1.0),)),\n",
       " (('a', 'tone'), 1, (('deaf', 1.0),)),\n",
       " (('tone', 'deaf'), 1, (('request', 1.0),)),\n",
       " (('deaf', 'request'), 1, (('.', 1.0),)),\n",
       " (('request', '.'), 1, (('</s>', 1.0),)),\n",
       " (('<s>', 'Also'),\n",
       "  3,\n",
       "  ((',', 0.6666666666666666), ('bringing', 0.3333333333333333))),\n",
       " (('Also', ','),\n",
       "  3,\n",
       "  (('it', 0.3333333333333333),\n",
       "   ('your', 0.3333333333333333),\n",
       "   ('if', 0.3333333333333333))),\n",
       " ((',', 'it'), 5, (('may', 0.2), ('should', 0.2), ('does', 0.2), (\"'s\", 0.4))),\n",
       " (('it', 'may'), 1, (('be', 1.0),)),\n",
       " (('may', 'be'), 1, (('unrelated', 1.0),)),\n",
       " (('be', 'unrelated'), 1, ((',', 1.0),)),\n",
       " (('unrelated', ','), 1, (('but', 1.0),)),\n",
       " ((',', 'but'),\n",
       "  10,\n",
       "  (('the', 0.2),\n",
       "   ('it', 0.2),\n",
       "   ('don', 0.1),\n",
       "   ('haven', 0.1),\n",
       "   ('I', 0.1),\n",
       "   ('you', 0.1),\n",
       "   ('still', 0.1),\n",
       "   ('how', 0.1))),\n",
       " (('but', 'the'), 2, (('“', 0.5), ('ones', 0.5))),\n",
       " (('the', '“'), 1, (('important', 1.0),)),\n",
       " (('“', 'important'), 1, (('to', 1.0),)),\n",
       " (('important', 'to'), 1, (('keep', 1.0),)),\n",
       " (('to', 'keep'), 2, (('this', 0.5), ('it', 0.5))),\n",
       " (('keep', 'this'), 1, (('surrogacy', 1.0),)),\n",
       " (('this', 'surrogacy'), 1, (('confined', 1.0),)),\n",
       " (('surrogacy', 'confined'), 1, (('to', 1.0),)),\n",
       " (('confined', 'to'), 1, (('his', 1.0),)),\n",
       " (('his', 'blood'), 1, (('”', 1.0),)),\n",
       " (('blood', '”'), 2, (('bit', 0.5), ('is', 0.5))),\n",
       " (('”', 'bit'), 1, (('makes', 1.0),)),\n",
       " (('bit', 'makes'), 1, (('me', 1.0),)),\n",
       " (('makes', 'me'),\n",
       "  3,\n",
       "  (('roll', 0.3333333333333333),\n",
       "   ('wonder', 0.3333333333333333),\n",
       "   ('feel', 0.3333333333333333))),\n",
       " (('me', 'roll'), 1, (('my', 1.0),)),\n",
       " (('roll', 'my'), 1, (('eyes', 1.0),)),\n",
       " (('my', 'eyes'), 1, (('so', 1.0),)),\n",
       " (('eyes', 'so'), 1, (('hard', 1.0),)),\n",
       " (('so', 'hard'), 1, (('.', 1.0),)),\n",
       " (('hard', '.'), 1, (('</s>', 1.0),)),\n",
       " (('<s>', 'Your'),\n",
       "  5,\n",
       "  (('parents', 0.4), ('request', 0.2), ('sister', 0.2), ('language', 0.2))),\n",
       " (('Your', 'parents'), 2, (('are', 0.5), ('think', 0.5))),\n",
       " (('parents', 'are'), 1, (('of', 1.0),)),\n",
       " (('are', 'of'), 1, (('course', 1.0),)),\n",
       " (('of', 'course'), 1, (('only', 1.0),)),\n",
       " (('course', 'only'), 1, (('going', 1.0),)),\n",
       " (('only', 'going'), 1, (('to', 1.0),)),\n",
       " (('going', 'to'), 1, (('see', 1.0),)),\n",
       " (('to', 'see'), 1, (('this', 1.0),)),\n",
       " (('see', 'this'), 1, (('from', 1.0),)),\n",
       " (('this', 'from'), 1, (('your', 1.0),)),\n",
       " (('from', 'your'), 2, (('point', 0.5), ('and', 0.5))),\n",
       " (('your', 'point'), 1, (('of', 1.0),)),\n",
       " (('point', 'of'), 1, (('view', 1.0),)),\n",
       " (('of', 'view'), 1, (('so', 1.0),)),\n",
       " (('view', 'so'), 1, (('their', 1.0),)),\n",
       " (('so', 'their'), 1, (('opinions', 1.0),)),\n",
       " (('their', 'opinions'), 1, (('on', 1.0),)),\n",
       " (('opinions', 'on'), 1, (('how', 1.0),)),\n",
       " (('on', 'how'), 2, (('your', 0.5), ('you', 0.5))),\n",
       " (('how', 'your'), 1, (('sister', 1.0),)),\n",
       " (('your', 'sister'), 5, (('in', 0.6), ('was', 0.2), ('just', 0.2))),\n",
       " (('sister', 'in'), 5, (('law', 1.0),)),\n",
       " (('in', 'law'), 5, (('feels', 0.2), ('’', 0.2), ('was', 0.2), ('.', 0.4))),\n",
       " (('law', 'feels'), 1, (('or', 1.0),)),\n",
       " (('feels', 'or'), 1, (('reacted', 1.0),)),\n",
       " (('or', 'reacted'), 1, (('are', 1.0),)),\n",
       " (('reacted', 'are'), 1, (('unnecessary', 1.0),)),\n",
       " (('are', 'unnecessary'), 1, (('.', 1.0),)),\n",
       " (('unnecessary', '.'), 1, (('</s>', 1.0),)),\n",
       " (('<s>', 'At'), 1, (('the', 1.0),)),\n",
       " (('At', 'the'), 1, (('end', 1.0),)),\n",
       " (('the', 'end'), 2, (('of', 0.5), ('(', 0.5))),\n",
       " (('end', 'of'), 1, (('the', 1.0),)),\n",
       " (('of', 'the'),\n",
       "  6,\n",
       "  (('day', 0.16666666666666666),\n",
       "   ('fact', 0.16666666666666666),\n",
       "   ('above', 0.16666666666666666),\n",
       "   ('time', 0.16666666666666666),\n",
       "   ('child', 0.16666666666666666),\n",
       "   ('story', 0.16666666666666666))),\n",
       " (('the', 'day'), 1, ((',', 1.0),)),\n",
       " (('day', ','), 1, (('you', 1.0),)),\n",
       " ((',', 'you'),\n",
       "  8,\n",
       "  (('guys', 0.125),\n",
       "   ('just', 0.125),\n",
       "   ('told', 0.125),\n",
       "   ('offered', 0.125),\n",
       "   (\"'re\", 0.125),\n",
       "   ('’', 0.125),\n",
       "   ('asked', 0.125),\n",
       "   ('went', 0.125))),\n",
       " (('you', 'guys'), 2, (('should', 0.5), ('knew', 0.5))),\n",
       " (('guys', 'should'), 1, (('have', 1.0),)),\n",
       " (('should', 'have'), 1, (('considered', 1.0),)),\n",
       " (('have', 'considered'), 1, (('your', 1.0),)),\n",
       " (('considered', 'your'), 1, (('sister', 1.0),)),\n",
       " (('law', '’'), 1, (('s', 1.0),)),\n",
       " (('’', 's'),\n",
       "  12,\n",
       "  (('feelings', 0.08333333333333333),\n",
       "   ('ready', 0.08333333333333333),\n",
       "   ('not', 0.08333333333333333),\n",
       "   ('child', 0.08333333333333333),\n",
       "   ('a', 0.08333333333333333),\n",
       "   ('sperm', 0.08333333333333333),\n",
       "   ('reaction', 0.08333333333333333),\n",
       "   ('all', 0.08333333333333333),\n",
       "   ('worth', 0.08333333333333333),\n",
       "   ('emotions', 0.08333333333333333),\n",
       "   ('no', 0.08333333333333333),\n",
       "   ('something', 0.08333333333333333))),\n",
       " (('s', 'feelings'), 1, (('way', 1.0),)),\n",
       " (('feelings', 'way'), 1, (('more', 1.0),)),\n",
       " (('way', 'more'), 1, (('than', 1.0),)),\n",
       " (('more', 'than'), 1, (('you', 1.0),)),\n",
       " (('than', 'you'), 1, (('did', 1.0),)),\n",
       " (('you', 'did'), 5, (('.', 0.2), ('all', 0.2), (\"n't\", 0.4), ('this', 0.2))),\n",
       " (('did', '.'), 1, (('</s>', 1.0),)),\n",
       " (('<s>', 'You'),\n",
       "  23,\n",
       "  (('asked', 0.08695652173913043),\n",
       "   ('’', 0.043478260869565216),\n",
       "   ('did', 0.043478260869565216),\n",
       "   ('wanting', 0.043478260869565216),\n",
       "   ('essentially', 0.043478260869565216),\n",
       "   ('sort', 0.043478260869565216),\n",
       "   ('certainly', 0.043478260869565216),\n",
       "   ('thought', 0.043478260869565216),\n",
       "   ('want', 0.043478260869565216),\n",
       "   ('don', 0.043478260869565216),\n",
       "   ('do', 0.08695652173913043),\n",
       "   (\"'re\", 0.08695652173913043),\n",
       "   ('disregarded', 0.043478260869565216),\n",
       "   ('knew', 0.043478260869565216),\n",
       "   ('act', 0.043478260869565216),\n",
       "   ('were', 0.043478260869565216),\n",
       "   ('clearly', 0.043478260869565216),\n",
       "   ('need', 0.043478260869565216),\n",
       "   (\"'ve\", 0.043478260869565216),\n",
       "   ('ask', 0.043478260869565216))),\n",
       " (('You', 'asked'), 2, (('a', 0.5), ('someone', 0.5))),\n",
       " (('asked', 'a'), 2, (('massive', 0.5), ('woman', 0.5))),\n",
       " (('a', 'massive'), 1, (('favor', 1.0),)),\n",
       " (('massive', 'favor'), 1, (('of', 1.0),)),\n",
       " (('favor', 'of'), 1, (('someone', 1.0),)),\n",
       " (('of', 'someone'), 2, (('who', 1.0),)),\n",
       " (('who', 'has'), 2, (('made', 0.5), ('chosen', 0.5))),\n",
       " (('has', 'made'), 1, (('clear', 1.0),)),\n",
       " (('made', 'clear'), 1, (('they', 1.0),)),\n",
       " (('clear', 'they'), 2, (('want', 0.5), ('will', 0.5))),\n",
       " (('they', 'want'), 1, (('nothing', 1.0),)),\n",
       " (('want', 'nothing'), 1, (('to', 1.0),)),\n",
       " (('nothing', 'to'), 2, (('do', 1.0),)),\n",
       " (('to', 'do'),\n",
       "  5,\n",
       "  (('with', 0.4), ('this', 0.2), ('you', 0.2), ('something', 0.2))),\n",
       " (('do', 'with'), 2, (('children', 0.5), ('it', 0.5))),\n",
       " (('with', 'children'), 1, ((',', 1.0),)),\n",
       " (('children', ','), 1, (('which', 1.0),)),\n",
       " ((',', 'which'), 1, (('probably', 1.0),)),\n",
       " (('which', 'probably'), 1, (('tells', 1.0),)),\n",
       " (('probably', 'tells'), 1, (('her', 1.0),)),\n",
       " (('tells', 'her'), 1, (('you', 1.0),)),\n",
       " (('her', 'you'), 1, (('don', 1.0),)),\n",
       " (('you', 'don'), 1, (('’', 1.0),)),\n",
       " (('don', '’'), 3, (('t', 1.0),)),\n",
       " (('’', 't'),\n",
       "  11,\n",
       "  (('care', 0.09090909090909091),\n",
       "   ('get', 0.09090909090909091),\n",
       "   ('mean', 0.09090909090909091),\n",
       "   ('have', 0.18181818181818182),\n",
       "   ('know', 0.09090909090909091),\n",
       "   ('want', 0.09090909090909091),\n",
       "   ('be', 0.09090909090909091),\n",
       "   ('had', 0.09090909090909091),\n",
       "   ('the', 0.09090909090909091),\n",
       "   ('opposed', 0.09090909090909091))),\n",
       " (('t', 'care'), 1, (('at', 1.0),)),\n",
       " (('care', 'at'), 1, (('all', 1.0),)),\n",
       " (('at', 'all'),\n",
       "  3,\n",
       "  (('about', 0.3333333333333333),\n",
       "   ('costs', 0.3333333333333333),\n",
       "   ('.', 0.3333333333333333))),\n",
       " (('all', 'about'), 1, (('her', 1.0),)),\n",
       " (('about', 'her'),\n",
       "  3,\n",
       "  (('or', 0.3333333333333333),\n",
       "   ('career', 0.3333333333333333),\n",
       "   ('maybe', 0.3333333333333333))),\n",
       " (('her', 'or'), 1, (('the', 1.0),)),\n",
       " (('or', 'the'), 1, (('things', 1.0),)),\n",
       " (('the', 'things'), 1, (('she', 1.0),)),\n",
       " (('things', 'she'), 1, (('wants', 1.0),)),\n",
       " (('she', 'wants'), 2, (('for', 0.5), (',', 0.5))),\n",
       " (('wants', 'for'), 1, (('her', 1.0),)),\n",
       " (('for', 'her'),\n",
       "  3,\n",
       "  (('life', 0.3333333333333333), ('.', 0.6666666666666666))),\n",
       " (('her', 'life'), 1, ((',', 1.0),)),\n",
       " (('life', ','), 1, (('you', 1.0),)),\n",
       " (('you', 'just'),\n",
       "  3,\n",
       "  (('saw', 0.3333333333333333),\n",
       "   ('kept', 0.3333333333333333),\n",
       "   ('hire', 0.3333333333333333))),\n",
       " (('just', 'saw'), 1, (('her', 1.0),)),\n",
       " (('saw', 'her'), 1, (('as', 1.0),)),\n",
       " (('her', 'as'), 3, (('a', 0.6666666666666666), ('much', 0.3333333333333333))),\n",
       " (('as', 'a'),\n",
       "  4,\n",
       "  (('potential', 0.25),\n",
       "   ('regular', 0.25),\n",
       "   ('human', 0.25),\n",
       "   ('surrogate', 0.25))),\n",
       " (('a', 'potential'), 1, (('womb', 1.0),)),\n",
       " (('potential', 'womb'), 1, (('.', 1.0),)),\n",
       " (('womb', '.'), 2, (('</s>', 1.0),)),\n",
       " (('You', '’'), 1, (('d', 1.0),)),\n",
       " (('’', 'd'), 2, (('probably', 0.5), ('say', 0.5))),\n",
       " (('d', 'probably'), 1, (('do', 1.0),)),\n",
       " (('probably', 'do'), 1, (('well', 1.0),)),\n",
       " (('do', 'well'), 1, (('to', 1.0),)),\n",
       " (('well', 'to'), 1, (('hold', 1.0),)),\n",
       " (('to', 'hold'), 1, (('off', 1.0),)),\n",
       " (('hold', 'off'), 1, (('on', 1.0),)),\n",
       " (('off', 'on'), 1, (('contacting', 1.0),)),\n",
       " (('on', 'contacting'), 1, (('her', 1.0),)),\n",
       " (('contacting', 'her'), 1, (('until', 1.0),)),\n",
       " (('her', 'until'), 1, (('she', 1.0),)),\n",
       " (('until', 'she'), 2, (('’', 0.5), ('comes', 0.5))),\n",
       " (('she', '’'), 1, (('s', 1.0),)),\n",
       " (('s', 'ready'), 1, (('.', 1.0),)),\n",
       " (('ready', '.'), 1, (('</s>', 1.0),)),\n",
       " (('</s>', '</c>'), 23, (('<c>', 1.0),)),\n",
       " (('</c>', '<c>'), 23, (('<s>', 1.0),)),\n",
       " (('YTA', 'Honestly'), 1, ((',', 1.0),)),\n",
       " (('Honestly', ','), 1, (('it', 1.0),)),\n",
       " (('it', 'should'), 1, (('be', 1.0),)),\n",
       " (('should', 'be'), 1, (('expected', 1.0),)),\n",
       " (('be', 'expected'), 1, (('that', 1.0),)),\n",
       " (('expected', 'that'), 1, (('a', 1.0),)),\n",
       " (('that', 'a'), 2, (('woman', 1.0),)),\n",
       " (('a', 'woman'), 3, (('who', 1.0),)),\n",
       " (('woman', 'who'),\n",
       "  3,\n",
       "  (('wants', 0.3333333333333333),\n",
       "   ('hates', 0.3333333333333333),\n",
       "   ('does', 0.3333333333333333))),\n",
       " (('who', 'wants'), 1, (('no', 1.0),)),\n",
       " (('wants', 'no'), 1, (('kids', 1.0),)),\n",
       " (('no', 'kids'), 1, (('would', 1.0),)),\n",
       " (('kids', 'would'), 1, (('also', 1.0),)),\n",
       " (('would', 'also'), 2, (('not', 0.5), ('just', 0.5))),\n",
       " (('also', 'not'), 1, (('want', 1.0),)),\n",
       " (('not', 'want'), 2, (('her', 0.5), ('kids', 0.5))),\n",
       " (('want', 'her'), 1, (('body', 1.0),)),\n",
       " (('her', 'body'),\n",
       "  3,\n",
       "  (('used', 0.3333333333333333),\n",
       "   ('would', 0.3333333333333333),\n",
       "   ('.', 0.3333333333333333))),\n",
       " (('body', 'used'), 1, (('for', 1.0),)),\n",
       " (('used', 'for'), 1, (('the', 1.0),)),\n",
       " (('for', 'the'),\n",
       "  3,\n",
       "  (('very', 0.3333333333333333),\n",
       "   ('ask', 0.3333333333333333),\n",
       "   ('third', 0.3333333333333333))),\n",
       " (('the', 'very'), 1, (('thing', 1.0),)),\n",
       " (('very', 'thing'), 1, (('she', 1.0),)),\n",
       " (('thing', 'she'), 1, (('is', 1.0),)),\n",
       " (('she', 'is'),\n",
       "  3,\n",
       "  (('so', 0.3333333333333333),\n",
       "   ('etc', 0.3333333333333333),\n",
       "   ('fundamentally', 0.3333333333333333))),\n",
       " (('is', 'so'), 1, (('against', 1.0),)),\n",
       " (('so', 'against'), 1, (('.', 1.0),)),\n",
       " (('against', '.'), 2, (('</s>', 1.0),)),\n",
       " (('<s>', 'It'),\n",
       "  7,\n",
       "  ((\"'s\", 0.5714285714285714),\n",
       "   ('may', 0.14285714285714285),\n",
       "   ('sounds', 0.14285714285714285),\n",
       "   ('makes', 0.14285714285714285))),\n",
       " (('It', \"'s\"),\n",
       "  4,\n",
       "  (('inappropriate', 0.25), ('actually', 0.25), ('a', 0.25), ('not', 0.25))),\n",
       " ((\"'s\", 'inappropriate'), 1, (('and', 1.0),)),\n",
       " (('inappropriate', 'and'), 1, (('disrespectful', 1.0),)),\n",
       " (('and', 'disrespectful'), 1, (('as', 1.0),)),\n",
       " (('disrespectful', 'as'), 1, (('hell', 1.0),)),\n",
       " (('as', 'hell'), 1, (('to', 1.0),)),\n",
       " (('hell', 'to'), 1, (('ask', 1.0),)),\n",
       " (('to', 'ask'),\n",
       "  6,\n",
       "  (('that', 0.16666666666666666),\n",
       "   ('her', 0.5),\n",
       "   ('a', 0.16666666666666666),\n",
       "   ('someone', 0.16666666666666666))),\n",
       " (('ask', 'that'), 1, (('of', 1.0),)),\n",
       " (('that', 'of'), 1, (('someone', 1.0),)),\n",
       " (('who', 'would'), 1, (('by', 1.0),)),\n",
       " (('would', 'by'), 1, (('all', 1.0),)),\n",
       " (('by', 'all'), 1, (('means', 1.0),)),\n",
       " (('all', 'means'), 1, (('be', 1.0),)),\n",
       " (('means', 'be'), 1, (('against', 1.0),)),\n",
       " (('be', 'against'), 1, (('it', 1.0),)),\n",
       " (('against', 'it'), 1, (('.', 1.0),)),\n",
       " (('it', '.'), 6, (('</s>', 1.0),)),\n",
       " (('You', 'did'), 1, ((\"n't\", 1.0),)),\n",
       " (('did', \"n't\"),\n",
       "  3,\n",
       "  (('just', 0.3333333333333333),\n",
       "   ('clarify', 0.3333333333333333),\n",
       "   ('take', 0.3333333333333333))),\n",
       " ((\"n't\", 'just'), 1, (('ask', 1.0),)),\n",
       " (('just', 'ask'), 1, (('her', 1.0),)),\n",
       " (('ask', 'her'), 4, (('to', 0.25), ('this', 0.25), ('.', 0.5))),\n",
       " (('her', 'to'),\n",
       "  4,\n",
       "  (('be', 0.25), ('perform', 0.25), ('look', 0.25), ('your', 0.25))),\n",
       " (('to', 'be'),\n",
       "  10,\n",
       "  (('a', 0.2),\n",
       "   ('unable', 0.1),\n",
       "   ('extra', 0.1),\n",
       "   ('pregnant', 0.3),\n",
       "   ('raised', 0.1),\n",
       "   ('offended', 0.1),\n",
       "   ('considered', 0.1))),\n",
       " (('be', 'a'),\n",
       "  6,\n",
       "  (('surrogate', 0.6666666666666666),\n",
       "   ('delicate', 0.16666666666666666),\n",
       "   ('bit', 0.16666666666666666))),\n",
       " (('a', 'surrogate'),\n",
       "  8,\n",
       "  ((',', 0.25),\n",
       "   ('then', 0.125),\n",
       "   ('.', 0.125),\n",
       "   ('is', 0.125),\n",
       "   ('?', 0.125),\n",
       "   ('for', 0.125),\n",
       "   ('that', 0.125))),\n",
       " (('surrogate', ','), 2, (('you', 0.5), ('do', 0.5))),\n",
       " (('you', 'told'), 1, (('her', 1.0),)),\n",
       " (('told', 'her'), 1, (('that', 1.0),)),\n",
       " (('her', 'that'), 1, (('you', 1.0),)),\n",
       " (('that', 'you'),\n",
       "  5,\n",
       "  (('do', 0.2), ('can', 0.2), ('would', 0.2), ('are', 0.2), (\"'re\", 0.2))),\n",
       " (('you', 'do'), 3, ((\"n't\", 1.0),)),\n",
       " (('do', \"n't\"),\n",
       "  12,\n",
       "  (('give', 0.08333333333333333),\n",
       "   ('try', 0.08333333333333333),\n",
       "   ('want', 0.5),\n",
       "   ('have', 0.08333333333333333),\n",
       "   ('need', 0.08333333333333333),\n",
       "   ('respect', 0.08333333333333333),\n",
       "   ('know', 0.08333333333333333))),\n",
       " ((\"n't\", 'give'), 1, (('a', 1.0),)),\n",
       " (('give', 'a'), 1, (('damn', 1.0),)),\n",
       " (('a', 'damn'), 1, (('about', 1.0),)),\n",
       " (('damn', 'about'), 1, (('what', 1.0),)),\n",
       " (('about', 'what'), 2, (('she', 1.0),)),\n",
       " (('what', 'she'),\n",
       "  4,\n",
       "  (('wants', 0.25), ('is', 0.25), ('does', 0.25), ('MEANT', 0.25))),\n",
       " (('wants', ','), 1, (('and', 1.0),)),\n",
       " ((',', 'and'),\n",
       "  9,\n",
       "  (('that', 0.1111111111111111),\n",
       "   ('then', 0.1111111111111111),\n",
       "   ('angry', 0.1111111111111111),\n",
       "   ('when', 0.1111111111111111),\n",
       "   ('your', 0.1111111111111111),\n",
       "   ('you', 0.2222222222222222),\n",
       "   ('it', 0.1111111111111111),\n",
       "   ('medically', 0.1111111111111111))),\n",
       " (('and', 'that'), 2, (('her', 0.5), (\"'s\", 0.5))),\n",
       " (('that', 'her'), 1, (('childfree', 1.0),)),\n",
       " (('her', 'childfree'), 1, (('status', 1.0),)),\n",
       " (('childfree', 'status'), 1, (('means', 1.0),)),\n",
       " (('status', 'means'), 1, (('jack', 1.0),)),\n",
       " (('means', 'jack'), 1, (('shit', 1.0),)),\n",
       " (('jack', 'shit'), 1, (('to', 1.0),)),\n",
       " (('shit', 'to'), 1, (('you', 1.0),)),\n",
       " (('to', 'you'),\n",
       "  7,\n",
       "  (('.', 0.42857142857142855),\n",
       "   ('?', 0.14285714285714285),\n",
       "   ('asking', 0.14285714285714285),\n",
       "   (',', 0.14285714285714285),\n",
       "   ('or', 0.14285714285714285))),\n",
       " (('you', '.'), 4, (('</s>', 1.0),)),\n",
       " (('You', 'wanting'), 1, (('to', 1.0),)),\n",
       " (('wanting', 'to'),\n",
       "  5,\n",
       "  (('have', 0.4), ('stay', 0.2), ('bear', 0.2), ('be', 0.2))),\n",
       " (('to', 'have'),\n",
       "  8,\n",
       "  (('kids', 0.25),\n",
       "   ('children', 0.125),\n",
       "   ('a', 0.125),\n",
       "   ('when', 0.125),\n",
       "   ('them', 0.125),\n",
       "   ('given', 0.125),\n",
       "   ('sex', 0.125))),\n",
       " (('have', 'kids'),\n",
       "  4,\n",
       "  (('is', 0.25), ('anymore', 0.25), ('to', 0.25), ('and', 0.25))),\n",
       " (('kids', 'is'), 1, (('not', 1.0),)),\n",
       " (('is', 'not'), 2, (('above', 0.5), ('something', 0.5))),\n",
       " (('not', 'above'), 1, (('her', 1.0),)),\n",
       " (('above', 'her'), 1, (('wanting', 1.0),)),\n",
       " (('her', 'wanting'), 1, (('to', 1.0),)),\n",
       " (('to', 'stay'), 2, (('childfree', 0.5), ('being', 0.5))),\n",
       " (('stay', 'childfree'), 1, (('and', 1.0),)),\n",
       " (('childfree', 'and'), 1, (('keep', 1.0),)),\n",
       " (('and', 'keep'), 1, (('her', 1.0),)),\n",
       " (('keep', 'her'), 1, (('womb', 1.0),)),\n",
       " (('her', 'womb'), 1, (('unused', 1.0),)),\n",
       " (('womb', 'unused'), 1, (('.', 1.0),)),\n",
       " (('unused', '.'), 1, (('</s>', 1.0),)),\n",
       " (('<s>', 'Edit'), 2, ((':', 1.0),)),\n",
       " (('Edit', ':'), 2, (('Also', 0.5), ('I', 0.5))),\n",
       " ((':', 'Also'), 1, ((',', 1.0),)),\n",
       " ((',', 'your'), 2, (('lack', 0.5), ('organs', 0.5))),\n",
       " (('your', 'lack'), 1, (('of', 1.0),)),\n",
       " (('lack', 'of'), 1, (('responding', 1.0),)),\n",
       " (('of', 'responding'), 1, (('to', 1.0),)),\n",
       " (('responding', 'to'), 1, (('comments', 1.0),)),\n",
       " (('to', 'comments'), 1, (('this', 1.0),)),\n",
       " (('comments', 'this'), 1, (('whole', 1.0),)),\n",
       " (('this', 'whole'), 1, (('time', 1.0),)),\n",
       " (('whole', 'time'), 1, (('makes', 1.0),)),\n",
       " (('time', 'makes'), 1, (('me', 1.0),)),\n",
       " (('me', 'wonder'), 1, (('if', 1.0),)),\n",
       " (('wonder', 'if'), 2, (('you', 1.0),)),\n",
       " (('if', 'you'),\n",
       "  5,\n",
       "  (('made', 0.2), ('just', 0.2), ('wanted', 0.2), (\"'re\", 0.2), ('had', 0.2))),\n",
       " (('you', 'made'), 1, (('this', 1.0),)),\n",
       " (('made', 'this'), 1, (('up', 1.0),)),\n",
       " (('this', 'up'), 1, (('to', 1.0),)),\n",
       " (('up', 'to'), 1, (('rile', 1.0),)),\n",
       " (('to', 'rile'), 1, (('people', 1.0),)),\n",
       " (('rile', 'people'), 1, (('up', 1.0),)),\n",
       " (('people', 'up'), 1, (('.', 1.0),)),\n",
       " (('up', '.'), 1, (('</s>', 1.0),)),\n",
       " (('<s>', 'And'),\n",
       "  11,\n",
       "  (('if', 0.09090909090909091),\n",
       "   ('whoever', 0.09090909090909091),\n",
       "   ('you', 0.18181818181818182),\n",
       "   ('the', 0.09090909090909091),\n",
       "   ('your', 0.09090909090909091),\n",
       "   ('can', 0.09090909090909091),\n",
       "   ('now', 0.09090909090909091),\n",
       "   ('for', 0.09090909090909091),\n",
       "   ('**no', 0.09090909090909091),\n",
       "   ('then', 0.09090909090909091))),\n",
       " (('And', 'if'), 1, (('not', 1.0),)),\n",
       " (('if', 'not'), 1, ((',', 1.0),)),\n",
       " (('not', ','), 1, (('then', 1.0),)),\n",
       " ((',', 'then'), 1, (('you', 1.0),)),\n",
       " (('then', 'you'), 1, (('are', 1.0),)),\n",
       " (('you', 'are'),\n",
       "  4,\n",
       "  (('either', 0.25),\n",
       "   ('asking', 0.25),\n",
       "   ('incredibly', 0.25),\n",
       "   ('desperate', 0.25))),\n",
       " (('are', 'either'), 1, (('leaving', 1.0),)),\n",
       " (('either', 'leaving'), 1, (('something', 1.0),)),\n",
       " (('leaving', 'something'), 1, (('out', 1.0),)),\n",
       " (('something', 'out'), 2, (('or', 0.5), ('of', 0.5))),\n",
       " (('out', 'or'), 1, (('are', 1.0),)),\n",
       " (('or', 'are'), 1, (('straight', 1.0),)),\n",
       " (('are', 'straight'), 1, (('up', 1.0),)),\n",
       " (('straight', 'up'), 1, (('lying', 1.0),)),\n",
       " (('up', 'lying'), 1, (('about', 1.0),)),\n",
       " (('lying', 'about'), 1, (('certain', 1.0),)),\n",
       " (('about', 'certain'), 1, (('shit', 1.0),)),\n",
       " (('certain', 'shit'), 1, (('.', 1.0),)),\n",
       " (('shit', '.'), 2, (('</s>', 1.0),)),\n",
       " (('If', 'she'), 1, (('``', 1.0),)),\n",
       " (('she', '``'), 1, (('exploded', 1.0),)),\n",
       " (('``', 'exploded'), 1, ((\"''\", 1.0),)),\n",
       " (('exploded', \"''\"), 1, (('then', 1.0),)),\n",
       " ((\"''\", 'then'), 1, (('I', 1.0),)),\n",
       " (('then', 'I'), 1, (('wonder', 1.0),)),\n",
       " (('I', 'wonder'), 1, (('if', 1.0),)),\n",
       " (('just', 'kept'), 1, (('being', 1.0),)),\n",
       " (('kept', 'being'), 1, (('up', 1.0),)),\n",
       " (('being', 'up'), 1, (('her', 1.0),)),\n",
       " (('up', 'her'), 1, (('ass', 1.0),)),\n",
       " (('her', 'ass'), 1, (('wanting', 1.0),)),\n",
       " (('ass', 'wanting'), 1, (('a', 1.0),)),\n",
       " (('wanting', 'a'), 1, (('yes', 1.0),)),\n",
       " (('a', 'yes'), 1, (('and', 1.0),)),\n",
       " (('yes', 'and'), 1, (('that', 1.0),)),\n",
       " (('that', \"'s\"),\n",
       "  3,\n",
       "  (('why', 0.3333333333333333),\n",
       "   ('directly', 0.3333333333333333),\n",
       "   ('always', 0.3333333333333333))),\n",
       " ((\"'s\", 'why'), 1, ((',', 1.0),)),\n",
       " (('why', ','), 1, (('or', 1.0),)),\n",
       " ((',', 'or'),\n",
       "  3,\n",
       "  (('she', 0.3333333333333333),\n",
       "   ('could', 0.3333333333333333),\n",
       "   ('all', 0.3333333333333333))),\n",
       " (('or', 'she'), 1, (('said', 1.0),)),\n",
       " (('she', 'said'), 1, (('no', 1.0),)),\n",
       " (('said', 'no'), 1, (('while', 1.0),)),\n",
       " (('no', 'while'), 1, (('being', 1.0),)),\n",
       " (('while', 'being'), 1, (('a', 1.0),)),\n",
       " (('being', 'a'), 1, (('bit', 1.0),)),\n",
       " (('a', 'bit'), 2, (('peeved', 0.5), ('annoyed', 0.5))),\n",
       " (('bit', 'peeved'), 1, (('and', 1.0),)),\n",
       " (('peeved', 'and'), 1, (('you', 1.0),)),\n",
       " (('and', 'you'),\n",
       "  5,\n",
       "  (('decided', 0.2),\n",
       "   ('asked', 0.2),\n",
       "   ('and', 0.2),\n",
       "   ('should', 0.2),\n",
       "   ('did', 0.2))),\n",
       " (('you', 'decided'), 1, (('that', 1.0),)),\n",
       " (('decided', 'that'), 1, (('equaled', 1.0),)),\n",
       " (('that', 'equaled'), 1, (('explosive', 1.0),)),\n",
       " (('equaled', 'explosive'), 1, (('.', 1.0),)),\n",
       " (('explosive', '.'), 1, (('</s>', 1.0),)),\n",
       " (('<s>', 'What'),\n",
       "  8,\n",
       "  (('are', 0.125),\n",
       "   ('about', 0.375),\n",
       "   ('the', 0.125),\n",
       "   ('if', 0.25),\n",
       "   ('result', 0.125))),\n",
       " (('What', 'are'), 1, (('you', 1.0),)),\n",
       " (('are', 'you'), 1, (('not', 1.0),)),\n",
       " (('you', 'not'), 2, (('telling', 0.5), ('understand', 0.5))),\n",
       " (('not', 'telling'), 1, (('us', 1.0),)),\n",
       " (('telling', 'us'), 1, ((',', 1.0),)),\n",
       " (('us', ','), 1, (('OP', 1.0),)),\n",
       " ((',', 'OP'), 1, (('?', 1.0),)),\n",
       " (('OP', '?'), 1, (('</s>', 1.0),)),\n",
       " (('YTA', 'for'), 2, (('thinking', 0.5), ('getting', 0.5))),\n",
       " (('for', 'thinking'), 1, (('that', 1.0),)),\n",
       " (('thinking', 'that'), 1, (('a', 1.0),)),\n",
       " (('who', 'hates'), 1, (('children', 1.0),)),\n",
       " (('hates', 'children'), 1, (('and', 1.0),)),\n",
       " (('children', 'and'), 2, (('has', 0.5), ('you', 0.5))),\n",
       " (('and', 'has'), 1, (('never', 1.0),)),\n",
       " (('has', 'never'), 1, (('carried', 1.0),)),\n",
       " (('never', 'carried'), 1, (('a', 1.0),)),\n",
       " (('carried', 'a'), 1, (('child', 1.0),)),\n",
       " (('a', 'child'),\n",
       "  6,\n",
       "  (('would', 0.16666666666666666),\n",
       "   ('does', 0.16666666666666666),\n",
       "   ('at', 0.16666666666666666),\n",
       "   ('genetically', 0.16666666666666666),\n",
       "   ('created', 0.16666666666666666),\n",
       "   ('you', 0.16666666666666666))),\n",
       " (('child', 'would'), 1, (('even', 1.0),)),\n",
       " (('would', 'even'), 2, (('be', 0.5), ('ask', 0.5))),\n",
       " (('even', 'be'), 1, (('accepted', 1.0),)),\n",
       " (('be', 'accepted'), 1, (('to', 1.0),)),\n",
       " (('accepted', 'to'), 1, (('a', 1.0),)),\n",
       " (('to', 'a'), 1, (('surrogacy', 1.0),)),\n",
       " (('a', 'surrogacy'), 1, (('program', 1.0),)),\n",
       " (('surrogacy', 'program'), 1, (('and', 1.0),)),\n",
       " (('program', 'and'), 1, (('also', 1.0),)),\n",
       " (('and', 'also'), 1, (('YTA', 1.0),)),\n",
       " (('also', 'YTA'), 1, (('for', 1.0),)),\n",
       " (('for', 'getting'), 1, (('all', 1.0),)),\n",
       " (('getting', 'all'), 1, (('upset', 1.0),)),\n",
       " (('all', 'upset'), 1, (('that', 1.0),)),\n",
       " (('upset', 'that'), 1, (('SIL', 1.0),)),\n",
       " (('that', 'SIL'), 1, (('does', 1.0),)),\n",
       " (('SIL', 'does'), 1, ((\"n't\", 1.0),)),\n",
       " (('does', \"n't\"), 8, (('want', 0.875), ('matter', 0.125))),\n",
       " ((\"n't\", 'want'),\n",
       "  13,\n",
       "  (('to', 0.3076923076923077),\n",
       "   ('children', 0.23076923076923078),\n",
       "   ('a', 0.07692307692307693),\n",
       "   ('and', 0.07692307692307693),\n",
       "   ('kids', 0.3076923076923077))),\n",
       " (('to', 'submit'), 1, (('to', 1.0),)),\n",
       " (('submit', 'to'), 1, (('your', 1.0),)),\n",
       " (('to', 'your'),\n",
       "  5,\n",
       "  (('weird', 0.2),\n",
       "   ('plight', 0.2),\n",
       "   ('husband', 0.2),\n",
       "   ('body', 0.2),\n",
       "   ('entire', 0.2))),\n",
       " (('your', 'weird'), 1, (('fucking', 1.0),)),\n",
       " (('weird', 'fucking'), 1, (('Handsmaid', 1.0),)),\n",
       " (('fucking', 'Handsmaid'), 1, ((\"'s\", 1.0),)),\n",
       " (('Handsmaid', \"'s\"), 1, (('Tale', 1.0),)),\n",
       " ((\"'s\", 'Tale'), 1, (('fantasy', 1.0),)),\n",
       " (('Tale', 'fantasy'), 1, (('.', 1.0),)),\n",
       " (('fantasy', '.'), 1, (('</s>', 1.0),)),\n",
       " (('YTA', '...'), 1, (('your', 1.0),)),\n",
       " (('...', 'your'), 1, (('desire', 1.0),)),\n",
       " (('your', 'desire'), 2, (('for', 1.0),)),\n",
       " (('desire', 'for'), 2, (('a', 0.5), ('wanting', 0.5))),\n",
       " (('for', 'a'),\n",
       "  6,\n",
       "  (('child', 0.5),\n",
       "   ('while', 0.16666666666666666),\n",
       "   ('surrogate', 0.16666666666666666),\n",
       "   ('couple', 0.16666666666666666))),\n",
       " (('child', 'does'), 1, (('not', 1.0),)),\n",
       " (('does', 'not'), 1, (('outweigh', 1.0),)),\n",
       " (('not', 'outweigh'), 1, (('your', 1.0),)),\n",
       " (('outweigh', 'your'), 1, (('SIL', 1.0),)),\n",
       " (('your', 'SIL'), 1, ((\"'s\", 1.0),)),\n",
       " (('SIL', \"'s\"), 1, (('desire', 1.0),)),\n",
       " ((\"'s\", 'desire'), 2, (('to', 1.0),)),\n",
       " (('desire', 'to'), 4, (('not', 0.25), ('avoid', 0.5), ('``', 0.25))),\n",
       " (('to', 'not'), 1, (('have', 1.0),)),\n",
       " (('not', 'have'), 1, (('children', 1.0),)),\n",
       " (('have', 'children'), 2, (('--', 0.5), ('-', 0.5))),\n",
       " (('children', '--'), 1, (('and', 1.0),)),\n",
       " (('--', 'and'), 1, (('it', 1.0),)),\n",
       " (('and', 'it'), 2, (('seems', 0.5), ('often', 0.5))),\n",
       " (('it', 'seems'), 1, (('both', 1.0),)),\n",
       " (('seems', 'both'), 1, (('are', 1.0),)),\n",
       " (('both', 'are'), 1, (('well', 1.0),)),\n",
       " (('are', 'well'), 1, (('known', 1.0),)),\n",
       " (('well', 'known'), 1, (('positions', 1.0),)),\n",
       " (('known', 'positions'), 1, (('in', 1.0),)),\n",
       " (('positions', 'in'), 1, (('the', 1.0),)),\n",
       " (('in', 'the'),\n",
       "  7,\n",
       "  (('family', 0.42857142857142855),\n",
       "   ('process', 0.14285714285714285),\n",
       "   ('cards', 0.14285714285714285),\n",
       "   ('world', 0.14285714285714285),\n",
       "   ('blood', 0.14285714285714285))),\n",
       " (('the', 'family'),\n",
       "  3,\n",
       "  (('.', 0.3333333333333333), (\"''\", 0.6666666666666666))),\n",
       " (('family', '.'), 1, (('</s>', 1.0),)),\n",
       " (('It', 'may'), 1, (('seem', 1.0),)),\n",
       " (('may', 'seem'), 1, (('reasonable', 1.0),)),\n",
       " (('seem', 'reasonable'), 1, (('to', 1.0),)),\n",
       " (('reasonable', 'to'), 1, (('``', 1.0),)),\n",
       " (('to', '``'), 2, (('keep', 1.0),)),\n",
       " (('``', 'keep'), 2, (('it', 1.0),)),\n",
       " (('keep', 'it'), 3, (('in', 0.6666666666666666), ('“', 0.3333333333333333))),\n",
       " (('it', 'in'), 2, (('the', 1.0),)),\n",
       " (('family', \"''\"), 2, (('and', 0.5), ('?', 0.5))),\n",
       " ((\"''\", 'and'), 1, (('``', 1.0),)),\n",
       " (('and', '``'), 1, (('we', 1.0),)),\n",
       " (('``', 'we'), 1, ((\"'re\", 1.0),)),\n",
       " (('we', \"'re\"), 1, (('trying', 1.0),)),\n",
       " ((\"'re\", 'trying'), 1, (('to', 1.0),)),\n",
       " (('to', 'create'), 1, (('a', 1.0),)),\n",
       " (('create', 'a'), 1, (('win-win', 1.0),)),\n",
       " (('a', 'win-win'), 1, ((\"''\", 1.0),)),\n",
       " (('win-win', \"''\"), 1, (('but', 1.0),)),\n",
       " ((\"''\", 'but'),\n",
       "  3,\n",
       "  (('really', 0.3333333333333333),\n",
       "   ('you', 0.3333333333333333),\n",
       "   ('are', 0.3333333333333333))),\n",
       " (('but', 'really'), 1, (('it', 1.0),)),\n",
       " (('really', 'it'), 1, (('is', 1.0),)),\n",
       " (('it', 'is'), 1, ((\"n't\", 1.0),)),\n",
       " (('is', \"n't\"),\n",
       "  3,\n",
       "  (('.', 0.3333333333333333),\n",
       "   ('repulsed', 0.3333333333333333),\n",
       "   ('hers', 0.3333333333333333))),\n",
       " ((\"n't\", '.'), 1, (('</s>', 1.0),)),\n",
       " (('You', 'essentially'), 1, (('said', 1.0),)),\n",
       " (('essentially', 'said'), 1, (('to', 1.0),)),\n",
       " (('said', 'to'), 1, (('her', 1.0),)),\n",
       " (('to', 'her'), 1, ((',', 1.0),)),\n",
       " (('her', ','),\n",
       "  3,\n",
       "  (('``', 0.3333333333333333),\n",
       "   ('to', 0.3333333333333333),\n",
       "   ('and', 0.3333333333333333))),\n",
       " ((',', '``'), 1, (('Since', 1.0),)),\n",
       " (('``', 'Since'), 1, (('you', 1.0),)),\n",
       " (('Since', 'you'), 1, ((\"'re\", 1.0),)),\n",
       " (('you', \"'re\"),\n",
       "  7,\n",
       "  (('not', 0.14285714285714285),\n",
       "   ('really', 0.14285714285714285),\n",
       "   ('telling', 0.14285714285714285),\n",
       "   ('baffled', 0.14285714285714285),\n",
       "   ('hiding', 0.14285714285714285),\n",
       "   ('the', 0.14285714285714285),\n",
       "   ('willing', 0.14285714285714285))),\n",
       " ((\"'re\", 'not'), 1, (('using', 1.0),)),\n",
       " (('not', 'using'), 1, (('your', 1.0),)),\n",
       " (('using', 'your'), 1, (('womb', 1.0),)),\n",
       " (('your', 'womb'), 2, (('mind', 0.5), ('.', 0.5))),\n",
       " (('womb', 'mind'), 1, (('if', 1.0),)),\n",
       " (('mind', 'if'), 1, (('we', 1.0),)),\n",
       " (('if', 'we'), 1, (('borrow', 1.0),)),\n",
       " (('we', 'borrow'), 1, (('it', 1.0),)),\n",
       " (('borrow', 'it'), 1, (('for', 1.0),)),\n",
       " (('it', 'for'), 2, (('9', 0.5), ('her', 0.5))),\n",
       " (('for', '9'), 2, (('months', 1.0),)),\n",
       " (('9', 'months'), 2, (('?', 0.5), (';', 0.5))),\n",
       " (('months', '?'), 1, ((\"''\", 1.0),)),\n",
       " (('?', \"''\"), 1, (('</s>', 1.0),)),\n",
       " ((\"''\", '</s>'),\n",
       "  3,\n",
       "  (('<s>', 0.6666666666666666), ('</c>', 0.3333333333333333))),\n",
       " (('<s>', 'Did'), 1, (('you', 1.0),)),\n",
       " (('Did', 'you'), 1, (('ever', 1.0),)),\n",
       " (('you', 'ever'), 1, (('consider', 1.0),)),\n",
       " (('ever', 'consider'), 1, (('why', 1.0),)),\n",
       " (('consider', 'why'), 1, (('she', 1.0),)),\n",
       " (('why', 'she'), 1, (('does', 1.0),)),\n",
       " (('she', 'does'), 5, ((\"n't\", 0.6), (',', 0.2), ('with', 0.2))),\n",
       " (('want', 'children'),\n",
       "  3,\n",
       "  (('of', 0.3333333333333333),\n",
       "   (\"''\", 0.3333333333333333),\n",
       "   ('.', 0.3333333333333333))),\n",
       " (('children', 'of'), 2, (('her', 1.0),)),\n",
       " (('of', 'her'), 4, (('own', 0.75), ('.', 0.25))),\n",
       " (('her', 'own'),\n",
       "  3,\n",
       "  (('?', 0.3333333333333333),\n",
       "   ('.', 0.3333333333333333),\n",
       "   (\"''\", 0.3333333333333333))),\n",
       " (('own', '?'), 1, (('</s>', 1.0),)),\n",
       " ((\"'s\", 'actually'), 1, (('beyond', 1.0),)),\n",
       " (('actually', 'beyond'), 1, (('rude', 1.0),)),\n",
       " (('beyond', 'rude'), 1, (('the', 1.0),)),\n",
       " (('rude', 'the'), 1, (('more', 1.0),)),\n",
       " (('the', 'more'), 2, (('I', 1.0),)),\n",
       " (('more', 'I'), 2, (('consider', 0.5), ('understand', 0.5))),\n",
       " (('I', 'consider'), 1, (('it', 1.0),)),\n",
       " (('consider', 'it'), 1, (('.', 1.0),)),\n",
       " (('<s>', 'Yes'), 1, ((',', 1.0),)),\n",
       " (('Yes', ','), 1, (('I', 1.0),)),\n",
       " (('I', 'am'), 2, (('sympathetic', 0.5), ('and', 0.5))),\n",
       " (('am', 'sympathetic'), 1, (('to', 1.0),)),\n",
       " (('sympathetic', 'to'), 1, (('your', 1.0),)),\n",
       " (('your', 'plight'), 1, (('but', 1.0),)),\n",
       " (('plight', 'but'), 1, (('have', 1.0),)),\n",
       " (('but', 'have'), 1, (('only', 1.0),)),\n",
       " (('have', 'only'), 1, (('one', 1.0),)),\n",
       " (('only', 'one'), 1, (('more', 1.0),)),\n",
       " (('one', 'more'), 1, (('word', 1.0),)),\n",
       " (('more', 'word'), 1, (('for', 1.0),)),\n",
       " (('word', 'for'), 1, (('you', 1.0),)),\n",
       " (('for', 'you'), 1, ((':', 1.0),)),\n",
       " (('you', ':'), 1, (('ADOPTION', 1.0),)),\n",
       " ((':', 'ADOPTION'), 1, (('!', 1.0),)),\n",
       " (('ADOPTION', '!'), 1, (('</s>', 1.0),)),\n",
       " (('!', '</s>'), 5, (('</c>', 0.2), ('<s>', 0.8))),\n",
       " (('You', 'sort'), 1, (('of', 1.0),)),\n",
       " (('sort', 'of'), 1, (('set', 1.0),)),\n",
       " (('of', 'set'), 1, (('her', 1.0),)),\n",
       " (('set', 'her'), 1, (('up', 1.0),)),\n",
       " (('her', 'up'), 1, ((',', 1.0),)),\n",
       " (('up', ','), 1, (('inviting', 1.0),)),\n",
       " ((',', 'inviting'), 1, (('her', 1.0),)),\n",
       " (('inviting', 'her'), 1, (('for', 1.0),)),\n",
       " (('her', 'for'), 1, (('dinner', 1.0),)),\n",
       " (('for', 'dinner'), 1, (('actually', 1.0),)),\n",
       " (('dinner', 'actually'), 1, (('to', 1.0),)),\n",
       " (('actually', 'to'), 1, (('ask', 1.0),)),\n",
       " (('her', 'this'), 1, ((',', 1.0),)),\n",
       " (('this', ','),\n",
       "  3,\n",
       "  (('having', 0.3333333333333333),\n",
       "   ('but', 0.3333333333333333),\n",
       "   ('because', 0.3333333333333333))),\n",
       " ((',', 'having'), 1, (('prepared', 1.0),)),\n",
       " (('having', 'prepared'), 1, (('all', 1.0),)),\n",
       " (('prepared', 'all'), 1, (('your', 1.0),)),\n",
       " (('all', 'your'), 1, (('points', 1.0),)),\n",
       " (('your', 'points'), 1, (('beforehand', 1.0),)),\n",
       " (('points', 'beforehand'), 1, (('.', 1.0),)),\n",
       " (('beforehand', '.'), 1, (('</s>', 1.0),)),\n",
       " (('You', 'certainly'), 1, (('knew', 1.0),)),\n",
       " (('certainly', 'knew'), 1, (('it', 1.0),)),\n",
       " (('knew', 'it'), 1, (('would', 1.0),)),\n",
       " (('it', 'would'),\n",
       "  3,\n",
       "  (('be', 0.6666666666666666), ('also', 0.3333333333333333))),\n",
       " (('would', 'be'), 2, (('a', 0.5), ('to', 0.5))),\n",
       " (('a', 'delicate'), 1, (('matter', 1.0),)),\n",
       " (('delicate', 'matter'), 1, (('.', 1.0),)),\n",
       " (('matter', '.'), 1, (('</s>', 1.0),)),\n",
       " (('Your', 'request'), 1, (('was', 1.0),)),\n",
       " (('request', 'was'), 1, (('very', 1.0),)),\n",
       " (('was', 'very'), 1, (('selfish', 1.0),)),\n",
       " (('very', 'selfish'), 1, ((',', 1.0),)),\n",
       " (('selfish', ','), 1, (('what', 1.0),)),\n",
       " ((',', 'what'), 1, (('is', 1.0),)),\n",
       " (('what', 'is'), 1, (('it', 1.0),)),\n",
       " (('is', 'it'), 2, (('about', 0.5), ('ok', 0.5))),\n",
       " (('it', 'about'), 1, (('keeping', 1.0),)),\n",
       " (('about', 'keeping'), 1, (('the', 1.0),)),\n",
       " (('keeping', 'the'), 1, (('process', 1.0),)),\n",
       " (('the', 'process'), 2, (('in', 0.5), ('.', 0.5))),\n",
       " (('process', 'in'), 1, (('your', 1.0),)),\n",
       " (('in', 'your'),\n",
       "  3,\n",
       "  (('husband', 0.3333333333333333),\n",
       "   ('womb', 0.3333333333333333),\n",
       "   ('bloodline', 0.3333333333333333))),\n",
       " (('husband', \"'s\"),\n",
       "  3,\n",
       "  (('blood', 0.3333333333333333),\n",
       "   ('parents', 0.3333333333333333),\n",
       "   ('desire', 0.3333333333333333))),\n",
       " ((\"'s\", 'blood'), 1, (('?', 1.0),)),\n",
       " (('blood', '?'), 1, (('</s>', 1.0),)),\n",
       " (('<s>', 'How'),\n",
       "  4,\n",
       "  (('is', 0.25), ('can', 0.25), ('many', 0.25), ('would', 0.25))),\n",
       " (('How', 'is'), 1, (('that', 1.0),)),\n",
       " (('that', 'more'), 1, (('important', 1.0),)),\n",
       " (('more', 'important'), 1, (('than', 1.0),)),\n",
       " (('important', 'than'), 1, (('the', 1.0),)),\n",
       " (('than', 'the'), 1, (('fact', 1.0),)),\n",
       " (('the', 'fact'), 4, (('that', 1.0),)),\n",
       " (('fact', 'that'),\n",
       "  4,\n",
       "  (('his', 0.25), ('you', 0.25), ('pregnancy', 0.25), ('everyone', 0.25))),\n",
       " (('that', 'his'), 1, (('sister', 1.0),)),\n",
       " (('sister', 'is'), 1, (('very', 1.0),)),\n",
       " (('is', 'very'), 2, (('clear', 1.0),)),\n",
       " (('very', 'clear'), 2, (('on', 0.5), ('they', 0.5))),\n",
       " (('clear', 'on'), 1, (('not', 1.0),)),\n",
       " (('on', 'not'), 1, (('wanting', 1.0),)),\n",
       " (('not', 'wanting'), 5, (('to', 0.6), ('kids', 0.4))),\n",
       " (('children', '-'), 1, (('which', 1.0),)),\n",
       " (('-', 'which'), 1, (('brings', 1.0),)),\n",
       " (('which', 'brings'), 1, (('a', 1.0),)),\n",
       " (('brings', 'a'), 1, (('high', 1.0),)),\n",
       " (('a', 'high'), 1, (('probability', 1.0),)),\n",
       " (('high', 'probability'), 1, (('of', 1.0),)),\n",
       " (('probability', 'of'), 1, (('not', 1.0),)),\n",
       " (('of', 'not'), 1, (('wanting', 1.0),)),\n",
       " (('to', 'bear'), 2, (('them', 0.5), ('your', 0.5))),\n",
       " (('bear', 'them'), 1, (('.', 1.0),)),\n",
       " (('them', '.'), 2, (('</s>', 1.0),)),\n",
       " (('You', 'thought'), 1, (('about', 1.0),)),\n",
       " (('thought', 'about'), 1, (('the', 1.0),)),\n",
       " (('about', 'the'),\n",
       "  3,\n",
       "  (('cost', 0.3333333333333333),\n",
       "   ('projects', 0.3333333333333333),\n",
       "   ('emotional', 0.3333333333333333))),\n",
       " (('the', 'cost'), 1, (('and', 1.0),)),\n",
       " (('cost', 'and'), 1, (('the', 1.0),)),\n",
       " (('and', 'the'), 1, (('conditions', 1.0),)),\n",
       " (('the', 'conditions'), 1, (('without', 1.0),)),\n",
       " (('conditions', 'without'), 1, (('even', 1.0),)),\n",
       " (('without', 'even'), 1, (('including', 1.0),)),\n",
       " (('even', 'including'), 1, (('her', 1.0),)),\n",
       " (('including', 'her'), 1, (('in', 1.0),)),\n",
       " (('her', 'in'), 1, (('the', 1.0),)),\n",
       " (('process', '.'), 1, (('</s>', 1.0),)),\n",
       " (('<s>', 'Is'), 1, (('she', 1.0),)),\n",
       " (('Is', 'she'), 1, (('just', 1.0),)),\n",
       " (('she', 'just'), 1, (('a', 1.0),)),\n",
       " (('just', 'a'), 2, (('womb', 0.5), ('little', 0.5))),\n",
       " (('a', 'womb'), 1, (('to', 1.0),)),\n",
       " (('womb', 'to'), 1, (('you', 1.0),)),\n",
       " (('you', '?'), 1, (('</s>', 1.0),)),\n",
       " (('<s>', 'Surrogacy'), 1, (('is', 1.0),)),\n",
       " (('Surrogacy', 'is'), 1, (('not', 1.0),)),\n",
       " (('not', 'something'), 1, (('to', 1.0),)),\n",
       " (('something', 'to'), 1, (('take', 1.0),)),\n",
       " (('to', 'take'), 1, (('lightly', 1.0),)),\n",
       " (('take', 'lightly'), 1, (('.', 1.0),)),\n",
       " (('lightly', '.'), 1, (('</s>', 1.0),)),\n",
       " (('<s>', 'Being'), 1, (('pregnant', 1.0),)),\n",
       " (('Being', 'pregnant'), 1, (('changes', 1.0),)),\n",
       " (('pregnant', 'changes'), 1, (('your', 1.0),)),\n",
       " (('changes', 'your'), 2, (('whole', 0.5), ('body', 0.5))),\n",
       " (('your', 'whole'), 1, (('body', 1.0),)),\n",
       " (('whole', 'body'), 1, ((',', 1.0),)),\n",
       " (('body', ','),\n",
       "  3,\n",
       "  (('makes', 0.3333333333333333),\n",
       "   ('your', 0.3333333333333333),\n",
       "   ('it', 0.3333333333333333))),\n",
       " ((',', 'makes'), 1, (('you', 1.0),)),\n",
       " (('makes', 'you'), 1, (('unable', 1.0),)),\n",
       " (('you', 'unable'), 1, (('to', 1.0),)),\n",
       " (('unable', 'to'),\n",
       "  3,\n",
       "  (('work', 0.3333333333333333),\n",
       "   ('go', 0.3333333333333333),\n",
       "   ('have', 0.3333333333333333))),\n",
       " (('to', 'work'), 2, (('for', 0.5), ('and', 0.5))),\n",
       " (('work', 'for'), 1, (('a', 1.0),)),\n",
       " (('a', 'while'), 1, (('(', 1.0),)),\n",
       " (('while', '('), 1, (('great', 1.0),)),\n",
       " (('(', 'great'), 1, ((',', 1.0),)),\n",
       " (('great', ','), 1, (('you', 1.0),)),\n",
       " (('you', 'offered'), 1, (('her', 1.0),)),\n",
       " (('offered', 'her'), 1, (('money', 1.0),)),\n",
       " (('her', 'money'), 1, (('.', 1.0),)),\n",
       " (('money', '.'), 1, (('</s>', 1.0),)),\n",
       " (('What', 'about'),\n",
       "  3,\n",
       "  (('the', 0.3333333333333333), ('her', 0.6666666666666666))),\n",
       " (('the', 'projects'), 1, (('she', 1.0),)),\n",
       " (('projects', 'she'), 1, (('could', 1.0),)),\n",
       " (('she', 'could'), 1, ((\"n't\", 1.0),)),\n",
       " (('could', \"n't\"), 2, (('work', 0.5), ('seduce', 0.5))),\n",
       " ((\"n't\", 'work'), 1, (('on', 1.0),)),\n",
       " (('work', 'on'), 1, (('during', 1.0),)),\n",
       " (('on', 'during'), 1, (('that', 1.0),)),\n",
       " (('during', 'that'), 1, (('time', 1.0),)),\n",
       " (('that', 'time'), 1, (('?', 1.0),)),\n",
       " (('time', '?'), 1, (('</s>', 1.0),)),\n",
       " (('her', 'career'), 1, (('advancement', 1.0),)),\n",
       " (('career', 'advancement'), 1, (('?', 1.0),)),\n",
       " (('advancement', '?'), 1, (('</s>', 1.0),)),\n",
       " (('her', 'maybe'), 1, (('not', 1.0),)),\n",
       " (('maybe', 'not'), 1, (('wanting', 1.0),)),\n",
       " (('be', 'unable'), 1, (('to', 1.0),)),\n",
       " (('to', 'go'),\n",
       "  3,\n",
       "  (('to', 0.3333333333333333),\n",
       "   ('out', 0.3333333333333333),\n",
       "   ('through', 0.3333333333333333))),\n",
       " (('go', 'to'), 1, (('work', 1.0),)),\n",
       " (('work', 'and'), 1, (('to', 1.0),)),\n",
       " (('and', 'to'), 1, (('go', 1.0),)),\n",
       " (('go', 'out'), 1, (('to', 1.0),)),\n",
       " (('out', 'to'), 1, (('carry', 1.0),)),\n",
       " (('carry', 'your'), 1, (('kid', 1.0),)),\n",
       " (('your', 'kid'), 1, (('?', 1.0),)),\n",
       " (('kid', '?'), 1, (('</s>', 1.0),)),\n",
       " (('<s>', ')'), 1, ((',', 1.0),)),\n",
       " ((')', ','),\n",
       "  4,\n",
       "  (('stretches', 0.25), ('it', 0.25), ('and', 0.25), ('but', 0.25))),\n",
       " ((',', 'stretches'), 1, (('your', 1.0),)),\n",
       " (('stretches', 'your'), 1, (('body', 1.0),)),\n",
       " (('your', 'body'),\n",
       "  6,\n",
       "  ((',', 0.16666666666666666),\n",
       "   ('never', 0.16666666666666666),\n",
       "   ('?', 0.5),\n",
       "   ('and', 0.16666666666666666))),\n",
       " (('your', 'organs'), 1, ((',', 1.0),)),\n",
       " (('organs', ','), 1, (('puts', 1.0),)),\n",
       " ((',', 'puts'), 1, (('your', 1.0),)),\n",
       " (('puts', 'your'), 1, (('health', 1.0),)),\n",
       " (('your', 'health'), 1, (('at', 1.0),)),\n",
       " (('health', 'at'), 1, (('risk', 1.0),)),\n",
       " (('at', 'risk'), 1, (('.', 1.0),)),\n",
       " (('risk', '.'), 1, (('</s>', 1.0),)),\n",
       " ((\"'s\", 'a'), 2, (('big', 0.5), ('whole', 0.5))),\n",
       " (('a', 'big'), 1, (('change', 1.0),)),\n",
       " (('big', 'change'), 1, (('of', 1.0),)),\n",
       " (('change', 'of'), 1, (('lifestyle', 1.0),)),\n",
       " (('of', 'lifestyle'), 1, (('too', 1.0),)),\n",
       " (('lifestyle', 'too'), 1, (('(', 1.0),)),\n",
       " (('too', '('), 1, (('she', 1.0),)),\n",
       " (('(', 'she'), 1, ((\"'d\", 1.0),)),\n",
       " (('she', \"'d\"),\n",
       "  7,\n",
       "  (('have', 0.42857142857142855), ('be', 0.5714285714285714))),\n",
       " ((\"'d\", 'have'), 4, (('to', 0.75), ('reacted', 0.25))),\n",
       " (('have', 'to'),\n",
       "  5,\n",
       "  (('be', 0.2),\n",
       "   ('give', 0.2),\n",
       "   ('put', 0.2),\n",
       "   ('say', 0.2),\n",
       "   ('understand', 0.2))),\n",
       " (('be', 'extra'), 1, (('careful', 1.0),)),\n",
       " (('extra', 'careful'), 1, (('about', 1.0),)),\n",
       " (('careful', 'about'), 1, (('what', 1.0),)),\n",
       " (('is', 'etc'), 1, ((')', 1.0),)),\n",
       " (('etc', ')'), 1, (('.', 1.0),)),\n",
       " ((')', '.'), 2, (('</s>', 1.0),)),\n",
       " (('<s>', 'She'),\n",
       "  7,\n",
       "  ((\"'d\", 0.14285714285714285),\n",
       "   ('could', 0.14285714285714285),\n",
       "   ('does', 0.14285714285714285),\n",
       "   (\"'s\", 0.14285714285714285),\n",
       "   ('likely', 0.14285714285714285),\n",
       "   ('probably', 0.14285714285714285),\n",
       "   ('adamantly', 0.14285714285714285))),\n",
       " (('She', \"'d\"), 1, (('produce', 1.0),)),\n",
       " ((\"'d\", 'produce'), 1, (('hormones', 1.0),)),\n",
       " (('produce', 'hormones'), 1, (('that', 1.0),)),\n",
       " (('hormones', 'that'), 1, (('could', 1.0),)),\n",
       " (('that', 'could'), 1, (('make', 1.0),)),\n",
       " (('could', 'make'), 1, (('her', 1.0),)),\n",
       " (('make', 'her'), 1, (('emotionally', 1.0),)),\n",
       " (('her', 'emotionally'), 1, (('unstable', 1.0),)),\n",
       " (('emotionally', 'unstable'), 1, (('and/or', 1.0),)),\n",
       " (('unstable', 'and/or'), 1, (('attached', 1.0),)),\n",
       " (('and/or', 'attached'), 1, (('to', 1.0),)),\n",
       " (('attached', 'to'), 1, (('the', 1.0),)),\n",
       " (('to', 'the'),\n",
       "  3,\n",
       "  (('kid', 0.3333333333333333),\n",
       "   ('idea', 0.3333333333333333),\n",
       "   ('body', 0.3333333333333333))),\n",
       " (('the', 'kid'), 1, (('growing', 1.0),)),\n",
       " (('kid', 'growing'), 1, (('in', 1.0),)),\n",
       " (('growing', 'in'), 1, (('her', 1.0),)),\n",
       " (('in', 'her'), 2, (('belly', 0.5), ('body', 0.5))),\n",
       " (('her', 'belly'), 1, (('she', 1.0),)),\n",
       " (('belly', 'she'), 1, ((\"'d\", 1.0),)),\n",
       " (('to', 'give'), 1, (('up', 1.0),)),\n",
       " (('give', 'up'), 1, (('right', 1.0),)),\n",
       " (('up', 'right'), 1, (('away', 1.0),)),\n",
       " (('right', 'away'), 1, (('.', 1.0),)),\n",
       " (('away', '.'), 1, (('</s>', 1.0),)),\n",
       " (('<s>', 'Maybe'), 1, (('she', 1.0),)),\n",
       " (('Maybe', 'she'), 2, ((\"'d\", 0.5), ('wouldn', 0.5))),\n",
       " (('to', 'put'), 1, (('aside', 1.0),)),\n",
       " (('put', 'aside'), 1, (('dating', 1.0),)),\n",
       " (('aside', 'dating'), 1, (('and', 1.0),)),\n",
       " (('dating', 'and'), 1, (('all', 1.0),)),\n",
       " (('and', 'all'), 1, ((',', 1.0),)),\n",
       " (('all', ','), 1, (('or', 1.0),)),\n",
       " (('or', 'could'), 1, ((\"n't\", 1.0),)),\n",
       " ((\"n't\", 'seduce'), 1, (('the', 1.0),)),\n",
       " (('seduce', 'the'), 1, (('people', 1.0),)),\n",
       " (('the', 'people'), 1, (('she', 1.0),)),\n",
       " (('people', 'she'), 1, ((\"'d\", 1.0),)),\n",
       " ((\"'d\", 'be'),\n",
       "  5,\n",
       "  (('more', 0.2),\n",
       "   ('pregnant', 0.2),\n",
       "   ('ok', 0.2),\n",
       "   ('mad', 0.2),\n",
       "   ('having', 0.2))),\n",
       " (('be', 'more'), 1, (('attracted', 1.0),)),\n",
       " (('more', 'attracted'), 1, (('to', 1.0),)),\n",
       " (('attracted', 'to'), 1, (('(', 1.0),)),\n",
       " (('to', '('), 1, (('I', 1.0),)),\n",
       " (('(', 'I'), 1, ((\"'m\", 1.0),)),\n",
       " (('I', \"'m\"),\n",
       "  3,\n",
       "  (('thinking', 0.3333333333333333), ('not', 0.6666666666666666))),\n",
       " ((\"'m\", 'thinking'), 1, (('child-free', 1.0),)),\n",
       " (('thinking', 'child-free'), 1, (('people', 1.0),)),\n",
       " (('child-free', 'people'), 1, ((')', 1.0),)),\n",
       " (('people', ')'), 1, (('because', 1.0),)),\n",
       " ((')', 'because'), 1, (('she', 1.0),)),\n",
       " (('because', 'she'), 1, ((\"'d\", 1.0),)),\n",
       " (('be', 'pregnant'),\n",
       "  4,\n",
       "  (('.', 0.25), ('with', 0.25), (',', 0.25), ('ones', 0.25))),\n",
       " (('pregnant', '.'), 1, (('</s>', 1.0),)),\n",
       " (('<s>', 'The'),\n",
       "  3,\n",
       "  (('changes', 0.3333333333333333),\n",
       "   ('lengths', 0.3333333333333333),\n",
       "   ('most', 0.3333333333333333))),\n",
       " (('The', 'changes'), 1, (('in', 1.0),)),\n",
       " (('changes', 'in'), 1, (('her', 1.0),)),\n",
       " (('body', 'would'), 1, (('not', 1.0),)),\n",
       " (('would', 'not'), 1, (('be', 1.0),)),\n",
       " (('not', 'be'), 1, (('just', 1.0),)),\n",
       " (('be', 'just'), 1, (('for', 1.0),)),\n",
       " (('just', 'for'), 1, (('9', 1.0),)),\n",
       " (('months', ';'), 1, (('your', 1.0),)),\n",
       " ((';', 'your'), 1, (('body', 1.0),)),\n",
       " (('body', 'never'), 1, (('becomes', 1.0),)),\n",
       " (('never', 'becomes'), 1, (('the', 1.0),)),\n",
       " (('becomes', 'the'), 1, (('same', 1.0),)),\n",
       " (('the', 'same'),\n",
       "  3,\n",
       "  (('again', 0.3333333333333333),\n",
       "   ('way', 0.3333333333333333),\n",
       "   ('version', 0.3333333333333333))),\n",
       " (('same', 'again'), 1, (('.', 1.0),)),\n",
       " (('again', '.'), 1, (('</s>', 1.0),)),\n",
       " (('She', 'could'), 1, (('die', 1.0),)),\n",
       " (('could', 'die'), 1, (('giving', 1.0),)),\n",
       " (('die', 'giving'), 1, (('birth', 1.0),)),\n",
       " (('giving', 'birth'), 1, ((',', 1.0),)),\n",
       " (('birth', ','), 1, (('too', 1.0),)),\n",
       " ((',', 'too'), 1, (('.', 1.0),)),\n",
       " (('too', '.'), 2, (('</s>', 1.0),)),\n",
       " (('<s>', 'For'), 1, (('many', 1.0),)),\n",
       " (('For', 'many'), 1, (('people', 1.0),)),\n",
       " (('many', 'people'), 1, (('it', 1.0),)),\n",
       " (('people', 'it'), 1, (('would', 1.0),)),\n",
       " (('also', 'just'), 1, (('be', 1.0),)),\n",
       " (('just', 'be'), 1, (('freaking', 1.0),)),\n",
       " (('be', 'freaking'), 1, (('weird', 1.0),)),\n",
       " (('freaking', 'weird'), 1, (('to', 1.0),)),\n",
       " (('weird', 'to'), 1, (('be', 1.0),)),\n",
       " (('pregnant', 'with'), 2, (('their', 0.5), ('your', 0.5))),\n",
       " (('with', 'their'), 1, (('brother', 1.0),)),\n",
       " (('their', 'brother'), 1, ((\"'s\", 1.0),)),\n",
       " (('brother', \"'s\"), 2, (('kid', 0.5), ('baby', 0.5))),\n",
       " ((\"'s\", 'kid'), 1, (('.', 1.0),)),\n",
       " (('kid', '.'), 1, (('</s>', 1.0),)),\n",
       " (('<s>', 'There'),\n",
       "  6,\n",
       "  ((\"'s\", 0.3333333333333333),\n",
       "   ('are', 0.3333333333333333),\n",
       "   ('’', 0.3333333333333333))),\n",
       " (('There', \"'s\"), 2, (('absolutely', 0.5), ('a', 0.5))),\n",
       " ((\"'s\", 'absolutely'), 1, (('nothing', 1.0),)),\n",
       " (('absolutely', 'nothing'), 1, (('in', 1.0),)),\n",
       " (('nothing', 'in'), 1, (('it', 1.0),)),\n",
       " (('in', 'it'), 1, (('for', 1.0),)),\n",
       " (('her', '.'), 7, (('</s>', 1.0),)),\n",
       " (('You', 'want'), 1, (('a', 1.0),)),\n",
       " (('want', 'a'), 2, (('kid', 0.5), ('fetus', 0.5))),\n",
       " (('a', 'kid'),\n",
       "  3,\n",
       "  ((',', 0.3333333333333333),\n",
       "   ('anyways', 0.3333333333333333),\n",
       "   ('who', 0.3333333333333333))),\n",
       " (('kid', ','), 1, (('hire', 1.0),)),\n",
       " ((',', 'hire'), 1, (('somebody', 1.0),)),\n",
       " (('hire', 'somebody'), 1, (('who', 1.0),)),\n",
       " (('somebody', 'who'), 2, (('volunteers', 0.5), (\"'s\", 0.5))),\n",
       " (('who', 'volunteers'), 1, (('to', 1.0),)),\n",
       " (('volunteers', 'to'), 1, (('be', 1.0),)),\n",
       " ((',', 'do'), 1, ((\"n't\", 1.0),)),\n",
       " ((\"n't\", 'try'), 1, (('to', 1.0),)),\n",
       " (('try', 'to'), 2, (('convince', 0.5), ('fix', 0.5))),\n",
       " (('to', 'convince'), 1, (('somebody', 1.0),)),\n",
       " (('convince', 'somebody'), 1, (('who', 1.0),)),\n",
       " (('who', \"'s\"), 1, (('vocal', 1.0),)),\n",
       " ((\"'s\", 'vocal'), 1, (('about', 1.0),)),\n",
       " (('vocal', 'about'),\n",
       "  3,\n",
       "  (('not', 0.6666666666666666), ('hating', 0.3333333333333333))),\n",
       " (('about', 'not'), 2, (('wanting', 1.0),)),\n",
       " (('wanting', 'kids'), 2, (('to', 0.5), ('.', 0.5))),\n",
       " (('kids', 'to'), 2, (('bear', 0.5), ('carry', 0.5))),\n",
       " (('bear', 'your'), 1, (('child', 1.0),)),\n",
       " (('your', 'child'), 2, (('.', 0.5), (',', 0.5))),\n",
       " (('child', '.'), 2, (('</s>', 1.0),)),\n",
       " (('And', 'whoever'), 1, (('ends', 1.0),)),\n",
       " (('whoever', 'ends'), 1, (('up', 1.0),)),\n",
       " (('ends', 'up'), 1, (('bearing', 1.0),)),\n",
       " (('up', 'bearing'), 1, (('your', 1.0),)),\n",
       " (('bearing', 'your'), 1, (('child', 1.0),)),\n",
       " (('child', ','), 2, (('treat', 0.5), ('carry', 0.5))),\n",
       " ((',', 'treat'), 1, (('them', 1.0),)),\n",
       " (('treat', 'them'), 1, (('like', 1.0),)),\n",
       " (('them', 'like'), 1, (('a', 1.0),)),\n",
       " (('like', 'a'), 2, (('person', 0.5), ('walking', 0.5))),\n",
       " (('a', 'person'), 1, ((',', 1.0),)),\n",
       " (('person', ','), 1, (('not', 1.0),)),\n",
       " ((',', 'not'), 2, (('like', 0.5), ('kids', 0.5))),\n",
       " (('not', 'like'), 1, (('a', 1.0),)),\n",
       " (('a', 'walking'), 1, (('womb', 1.0),)),\n",
       " (('walking', 'womb'), 1, (('with', 1.0),)),\n",
       " (('womb', 'with'), 1, (('no', 1.0),)),\n",
       " (('with', 'no'), 1, (('opinion', 1.0),)),\n",
       " (('no', 'opinion'), 1, (('.', 1.0),)),\n",
       " (('opinion', '.'), 1, (('</s>', 1.0),)),\n",
       " (('The', 'lengths'), 1, (('people', 1.0),)),\n",
       " (('lengths', 'people'), 1, (('go', 1.0),)),\n",
       " (('people', 'go'), 1, (('for', 1.0),)),\n",
       " (('go', 'for'), 1, (('children', 1.0),)),\n",
       " (('for', 'children'), 1, (('when', 1.0),)),\n",
       " (('children', 'when'), 1, (('nature', 1.0),)),\n",
       " (('when', 'nature'), 1, (('says', 1.0),)),\n",
       " (('nature', 'says'), 1, (('over', 1.0),)),\n",
       " (('says', 'over'), 1, (('and', 1.0),)),\n",
       " (('over', 'and'), 1, (('over', 1.0),)),\n",
       " (('and', 'over'), 1, (('it', 1.0),)),\n",
       " (('over', 'it'), 1, (('’', 1.0),)),\n",
       " (('it', '’'), 3, (('s', 1.0),)),\n",
       " (('s', 'not'), 1, (('in', 1.0),)),\n",
       " (('not', 'in'), 1, (('the', 1.0),)),\n",
       " (('the', 'cards'), 1, (('for', 1.0),)),\n",
       " (('cards', 'for'), 1, (('them', 1.0),)),\n",
       " (('for', 'them'), 1, (('will', 1.0),)),\n",
       " (('them', 'will'), 1, (('never', 1.0),)),\n",
       " (('will', 'never'), 2, (('cease', 0.5), ('have', 0.5))),\n",
       " (('never', 'cease'), 1, (('to', 1.0),)),\n",
       " (('cease', 'to'), 1, (('astound', 1.0),)),\n",
       " (('to', 'astound'), 1, (('me', 1.0),)),\n",
       " (('astound', 'me'), 1, (('.', 1.0),)),\n",
       " (('me', '.'), 1, (('</s>', 1.0),)),\n",
       " (('Your', 'sister'), 1, (('in', 1.0),)),\n",
       " (('law', 'was'), 1, (('clearly', 1.0),)),\n",
       " (('was', 'clearly'), 1, (('anti', 1.0),)),\n",
       " (('clearly', 'anti'), 1, (('children', 1.0),)),\n",
       " (('anti', 'children'), 1, (('and', 1.0),)),\n",
       " (('you', 'asked'), 2, (('her', 0.5), ('a', 0.5))),\n",
       " (('asked', 'her'), 1, (('to', 1.0),)),\n",
       " (('to', 'perform'), 1, (('the', 1.0),)),\n",
       " (('perform', 'the'), 1, (('most', 1.0),)),\n",
       " (('the', 'most'), 1, (('difficult', 1.0),)),\n",
       " (('most', 'difficult'), 1, (('phase', 1.0),)),\n",
       " (('difficult', 'phase'), 1, (('of', 1.0),)),\n",
       " (('phase', 'of'), 1, (('having', 1.0),)),\n",
       " (('of', 'having'), 1, (('children', 1.0),)),\n",
       " (('children', 'for'), 1, (('your', 1.0),)),\n",
       " (('for', 'your'),\n",
       "  4,\n",
       "  (('own', 0.25), ('rudeass', 0.25), ('husband', 0.25), ('gain', 0.25))),\n",
       " (('your', 'own'), 2, (('child', 0.5), ('family', 0.5))),\n",
       " (('own', 'child'), 1, (('?', 1.0),)),\n",
       " (('child', '?'), 1, (('</s>', 1.0),)),\n",
       " (('I', 'get'), 1, (('that', 1.0),)),\n",
       " (('get', 'that'), 1, (('you', 1.0),)),\n",
       " (('you', 'can'),\n",
       "  3,\n",
       "  (('’', 0.3333333333333333),\n",
       "   ('try', 0.3333333333333333),\n",
       "   ('afford', 0.3333333333333333))),\n",
       " (('can', '’'), 1, (('t', 1.0),)),\n",
       " (('t', 'get'), 1, (('pregnant', 1.0),)),\n",
       " (('get', 'pregnant'), 2, (('yourself', 0.5), ('with', 0.5))),\n",
       " (('pregnant', 'yourself'), 1, (('but', 1.0),)),\n",
       " (('yourself', 'but'), 1, (('can', 1.0),)),\n",
       " (('but', 'can'), 1, (('you', 1.0),)),\n",
       " (('can', 'you'), 2, (('at', 0.5), ('not', 0.5))),\n",
       " (('you', 'at'), 1, (('least', 1.0),)),\n",
       " (('at', 'least'), 2, (('think', 0.5), ('I', 0.5))),\n",
       " (('least', 'think'), 1, (('about', 1.0),)),\n",
       " (('think', 'about'), 1, (('the', 1.0),)),\n",
       " (('the', 'emotional'), 1, (('toll', 1.0),)),\n",
       " (('emotional', 'toll'), 1, (('it', 1.0),)),\n",
       " (('toll', 'it'), 1, (('would', 1.0),)),\n",
       " (('be', 'to'), 1, (('get', 1.0),)),\n",
       " (('to', 'get'), 2, (('pregnant', 0.5), ('online', 0.5))),\n",
       " (('with', 'your'), 2, (('brother', 0.5), ('parents', 0.5))),\n",
       " (('your', 'brother'), 2, (('’', 0.5), ('and', 0.5))),\n",
       " (('brother', '’'), 1, (('s', 1.0),)),\n",
       " (('s', 'child'), 1, ((',', 1.0),)),\n",
       " ((',', 'carry'), 1, (('it', 1.0),)),\n",
       " (('carry', 'it'), 2, (('to', 0.5), ('.', 0.5))),\n",
       " (('it', 'to'), 1, (('term', 1.0),)),\n",
       " (('to', 'term'), 1, ((',', 1.0),)),\n",
       " (('term', ','), 1, (('GO', 1.0),)),\n",
       " ((',', 'GO'), 1, (('THROUGH', 1.0),)),\n",
       " (('GO', 'THROUGH'), 1, (('BIRTH', 1.0),)),\n",
       " (('THROUGH', 'BIRTH'), 1, ((',', 1.0),)),\n",
       " (('BIRTH', ','), 1, (('and', 1.0),)),\n",
       " (('and', 'then'), 2, (('no', 0.5), ('to', 0.5))),\n",
       " (('then', 'no'), 1, (('matter', 1.0),)),\n",
       " (('no', 'matter'), 2, (('if', 0.5), ('that', 0.5))),\n",
       " (('matter', 'if'), 2, (('your', 0.5), ('it', 0.5))),\n",
       " (('if', 'your'), 1, (('feelings', 1.0),)),\n",
       " (('your', 'feelings'), 1, (('change', 1.0),)),\n",
       " (('feelings', 'change'), 1, (('and', 1.0),)),\n",
       " (('change', 'and'), 1, (('transform', 1.0),)),\n",
       " (('and', 'transform'), 1, (('the', 1.0),)),\n",
       " (('transform', 'the'), 1, (('child', 1.0),)),\n",
       " (('the', 'child'), 2, (('YOU', 0.5), ('at', 0.5))),\n",
       " (('child', 'YOU'), 1, (('carried', 1.0),)),\n",
       " (('YOU', 'carried'), 1, (('is', 1.0),)),\n",
       " (('carried', 'is'), 1, (('then', 1.0),)),\n",
       " (('is', 'then'), 1, (('taken', 1.0),)),\n",
       " (('then', 'taken'), 1, (('from', 1.0),)),\n",
       " (('taken', 'from'), 1, (('you', 1.0),)),\n",
       " (('from', 'you'), 1, (('to', 1.0),)),\n",
       " (('you', 'to'),\n",
       "  3,\n",
       "  (('be', 0.3333333333333333),\n",
       "   ('carry', 0.3333333333333333),\n",
       "   ('“', 0.3333333333333333))),\n",
       " (('be', 'raised'), 1, (('by', 1.0),)),\n",
       " (('raised', 'by'), 1, (('your', 1.0),)),\n",
       " (('by', 'your'), 2, (('brother', 0.5), ('“', 0.5))),\n",
       " (('brother', 'and'), 1, (('sister', 1.0),)),\n",
       " (('and', 'sister'), 1, (('in', 1.0),)),\n",
       " (('law', '.'), 2, (('</s>', 1.0),)),\n",
       " (('How', 'can'), 1, (('you', 1.0),)),\n",
       " (('not', 'understand'), 1, (('the', 1.0),)),\n",
       " (('understand', 'the'),\n",
       "  3,\n",
       "  (('weight', 0.3333333333333333),\n",
       "   ('magnitude', 0.3333333333333333),\n",
       "   ('emotions', 0.3333333333333333))),\n",
       " (('the', 'weight'), 1, (('of', 1.0),)),\n",
       " (('weight', 'of'), 1, (('what', 1.0),)),\n",
       " (('of', 'what'), 2, (('you', 0.5), ('it', 0.5))),\n",
       " (('what', 'you'), 2, (('are', 0.5), ('have', 0.5))),\n",
       " (('are', 'asking'), 1, (('?', 1.0),)),\n",
       " (('asking', '?'), 1, (('</s>', 1.0),)),\n",
       " (('<s>', 'Oh'), 1, ((',', 1.0),)),\n",
       " (('Oh', ','), 1, (('but', 1.0),)),\n",
       " (('but', 'it'),\n",
       "  3,\n",
       "  (('means', 0.3333333333333333),\n",
       "   ('sounds', 0.3333333333333333),\n",
       "   ('quite', 0.3333333333333333))),\n",
       " (('it', 'means'), 1, (('so', 1.0),)),\n",
       " (('means', 'so'), 1, (('much', 1.0),)),\n",
       " (('so', 'much'), 1, (('to', 1.0),)),\n",
       " (('much', 'to'), 1, (('your', 1.0),)),\n",
       " (('husband', 'to'), 1, (('have', 1.0),)),\n",
       " (('have', 'a'), 2, (('blood', 0.5), ('right', 0.5))),\n",
       " (('a', 'blood'), 1, (('relative', 1.0),)),\n",
       " (('blood', 'relative'), 1, (('carry', 1.0),)),\n",
       " (('relative', 'carry'), 1, (('it', 1.0),)),\n",
       " (('What', 'the'), 1, (('actual', 1.0),)),\n",
       " (('the', 'actual'), 1, (('fuck', 1.0),)),\n",
       " (('actual', 'fuck'), 1, (('?', 1.0),)),\n",
       " (('fuck', '?'), 1, (('</s>', 1.0),)),\n",
       " (('If', 'you'),\n",
       "  3,\n",
       "  (('have', 0.3333333333333333),\n",
       "   ('do', 0.3333333333333333),\n",
       "   ('were', 0.3333333333333333))),\n",
       " (('you', 'have'), 4, (('the', 0.25), ('a', 0.25), ('0', 0.25), ('to', 0.25))),\n",
       " (('have', 'the'), 2, (('money', 0.5), ('right', 0.5))),\n",
       " (('the', 'money'), 1, (('for', 1.0),)),\n",
       " (('money', 'for'), 1, (('a', 1.0),)),\n",
       " (('surrogate', 'then'), 1, (('hire', 1.0),)),\n",
       " (('then', 'hire'), 1, (('a', 1.0),)),\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_generate_comment(corpus, N):\n",
    "    comment_starts = []\n",
    "    for gi  in corpus:\n",
    "        if gi[0][0] == '<c>':\n",
    "            comment_starts.append(gi)\n",
    "    num_starts = sum([gi[1] for gi in comment_starts])\n",
    "    probs=[gi[1]/num_starts for gi in comment_starts]\n",
    "    comment_start = comment_starts[np.random.choice(list(range(len(comment_starts))), p=probs)]\n",
    "    comment = [w for w in comment_start[0]]\n",
    "    while comment[-1] != '</c>':\n",
    "        prev_gram = tuple(comment[-(N-1):])\n",
    "        nnext_choices = None\n",
    "        for gi in corpus:\n",
    "            if gi[0] == prev_gram:\n",
    "                next_choices = gi[2]\n",
    "        if next_choices is not None:\n",
    "            next_probs = [x[1] for x in next_choices]\n",
    "            next_word = next_choices[np.random.choice(list(range(len(next_choices))),p=next_probs)][0]\n",
    "            comment.append(next_word)\n",
    "        else:\n",
    "            print('N-Gram not found in corpus')\n",
    "    return(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<c> <s> YTA - I know the I do n't have anyone ever asking that question but damn . </s> <s> That you had to prep her lavishly for the very thing she is so against . </s> <s> I think your desire for wanting children is outweighing your logic for other people ’ s a developmental defect and you and your husband 's desire to `` keep it “ in the family '' ? </s> <s> She 's never had kids . </s> <s> Asking someone to go to work for a while ( great , you told her that you are incredibly selfish for trying to create a win-win '' but you thought that she might not want kids ; hormones are a thing ) , and then to get online to complain about it . </s> <s> Mine worked out well , I am and I know you did n't just ask her . </s> <s> First of all unless you did all of the time a desire to `` keep it “ in the family '' ? </s> </c>\n",
      "<c> <s> YTA jesus christ , I also have not been able to have when she understandably got angry at you if you 're not using your womb . </s> </c>\n",
      "<c> <s> YTA . </s> <s> First of all unless you did all of this legally you could potentially be forcing her down a difficult road . </s> <s> It 's inappropriate and disrespectful as hell to ask her this , but the ones I do n't want kids '' but you approached her anyway without first finding out how far that extends . </s> <s> She 'd produce hormones that could make her emotionally unstable and/or attached to the body and mind . </s> <s> Also , it should be expected that a woman who does n't want to carry and birth her brother 's kid . </s> <s> The changes in her belly she 'd be mad too . </s> <s> Someone who is n't hers , but it quite often is , and then no matter that there are so many unwanted children in the family '' and `` we 're trying to turn the extended family against her , to pressure her into something she is so against . </s> <s> A get reasonable boundary to have them . </s> <s> How many miscarriages could she suffer ? </s> <s> Think about that , she 'd have to understand was a pretty massive ask of her own ? </s> <s> Fucking insane . </s> </c>\n",
      "<c> <s> YTA , because you did n't just ask her . </s> <s> She likely felt set up and in shock I am sympathetic to your body never becomes the same again . </s> <s> Childbirth absolutely *wrecks* your body ? </s> <s> And for what it does n't want children . </s> <s> I think you 're baffled and offended that she might not want her body would not be just for 9 months ; your body , makes you unable to go out to carry and birth a child does not outweigh your SIL 's desire to `` keep it in the family . </s> <s> ) , and angry that you would even ask . </s> <s> What if she has been vocal about not wanting kids . </s> </c>\n",
      "<c> <s> YTA . </s> <s> You ’ d probably do well to hold off on contacting her until she comes to you asking you to “ try a bite now , but it sounds like she 's behaving awfully ? ! </s> <s> You sort of set her up , inviting her for dinner actually to ask that of someone who has chosen that profession so people like you guys should have considered your sister just because he wants to keep it in the family . </s> <s> Why the fuck is it about keeping the process in your husband is that more important than the fact that pregnancy changes your whole body , makes you unable to have kids to carry yours ? </s> <s> First of all unless you did n't take the time a desire to `` keep it “ in the family . </s> </c>\n",
      "<c> <s> YTA . </s> <s> Maybe she 'd have to say that as kindly as possible but why would n't you just hire an actual surrogate . </s> <s> You 've not only invaded her boundaries ( you know the I do require the surrogates to have kids to carry and birth her brother 's kid . </s> <s> Many women in my bump group had major abdominal surgery . </s> <s> She adamantly does n't want children . </s> <s> Fucking insane . </s> <s> Also , your lack of responding to comments this whole time makes me wonder if you wanted to abort ? </s> <s> Because honestly , pregnancy takes a huge toll on the body , it should be expected that a woman who does n't want a fetus in your womb . </s> <s> How is that more important than the fact that pregnancy changes your body never becomes the same again . </s> <s> You sort of set her up , inviting her for dinner actually to ask that of someone who would by all means be against it . </s> <s> Which means she has been vocal about not wanting to have children -- and it often makes PERMANENT changes to the kid growing in her belly she 'd have to say that as kindly as possible but why would n't you just hire an actual surrogate . </s> <s> You certainly knew it would be to get online to complain about it . </s> <s> Oh , but I have to say it . </s> </c>\n",
      "<c> <s> YTA . </s> <s> If you do n't want kids period to have children -- and it often makes PERMANENT changes to the body and can put your life on hold for nine months . </s> <s> Edit : I ’ m not sure if she miscarries ? </s> <s> I do believe you have a right to be considered . </s> <s> You ask someone who has chosen that profession so people like you guys should have considered your sister in law . </s> <s> Yes , I also have not been able to have kids to bear your child , treat them like a walking womb with no opinion . </s> </c>\n",
      "<c> <s> YTA Honestly , it may be unrelated , but don ’ t had coffee yet so it ’ s not in the cards for them will never cease to astound me . </s> </c>\n",
      "<c> <s> YTA . </s> </c>\n",
      "<c> <s> YTA , because the fact that everyone 's on your side means they CA N'T have gotten the same way given I 've told people all my adult life I have to give up right away . </s> <s> It 's inappropriate and disrespectful as hell to ask her to your body ? </s> <s> There 's absolutely nothing in it for 9 months ; your body ? </s> <s> I get that you can ’ t know if the problem is your eggs and your husband ’ s a developmental defect and you decided that equaled explosive . </s> <s> You want a fetus in your bloodline . </s> </c>\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    comment = ' '.join(ngram_generate_comment(ngram_corpus, 3))\n",
    "    print(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, GRU, Dense, Activation\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rnn_corpus(cc, wv, N=10):\n",
    "    all_comments = []\n",
    "    all_words = []\n",
    "    category_inds = np.arange(len(judgement_categories))\n",
    "    np.random.shuffle(category_inds)\n",
    "\n",
    "    for category_ind in category_inds:\n",
    "        comments = cc[judgement_categories[category_ind]]\n",
    "        comment_inds = np.arange(len(comments))\n",
    "        np.random.shuffle(comment_inds)\n",
    "        for comment_ind in comment_inds:\n",
    "            all_comments.append(comments[comment_ind])\n",
    "            for token in comments[comment_ind]:\n",
    "                all_words.append(token)\n",
    "                \n",
    "    all_ngrams = ngrams(all_words,N)\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for ngram in all_ngrams:\n",
    "        X_train.append([wv[token] for token in ngram[:-1]])\n",
    "        y_train.append(wv[ngram[-1]])\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    return(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Word2Vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f48d425c5b23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mword2vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_comments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Word2Vec' is not defined"
     ]
    }
   ],
   "source": [
    "all_comments = []\n",
    "all_words = []\n",
    "category_inds = np.arange(len(judgement_categories))\n",
    "np.random.shuffle(category_inds)\n",
    "\n",
    "for category_ind in category_inds:\n",
    "    comments = cc[judgement_categories[category_ind]]\n",
    "    comment_inds = np.arange(len(comments))\n",
    "    np.random.shuffle(comment_inds)\n",
    "    for comment_ind in comment_inds:\n",
    "        all_comments.append(comments[comment_ind])\n",
    "        for token in comments[comment_ind]:\n",
    "            all_words.append(token)\n",
    "\n",
    "word2vec = Word2Vec(all_comments, min_count=1)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_ngrams = ngrams(all_words,5)\n",
    "#X_train = []\n",
    "#y_train = []\n",
    "#for ngram in all_ngrams:\n",
    "#    X_train.append([word2vec.wv[token] for token in ngram[:-1]])\n",
    "#    y_train.append(word2vec.wv[ngram[-1]])\n",
    "#    \n",
    "#X_train = np.array(X_train)\n",
    "#y_train = np.array(y_train)\n",
    "#X_train = np.array([word2vec.wv[token] for token in all_words])\n",
    "#y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, y_train = build_rnn_corpus(cc, word2vec.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(GRU(units=32, return_sequences=True))\n",
    "model.add(Dense(100))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_14 to have 3 dimensions, but got array with shape (3649, 100)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-ed1f6fccc25c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_rnn_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_14 to have 3 dimensions, but got array with shape (3649, 100)"
     ]
    }
   ],
   "source": [
    "X_train, y_train = build_rnn_corpus(cc, word2vec.wv)\n",
    "model.fit(X_train[:,:,:], y_train[:,:], shuffle=False, batch_size=16, epochs=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_train[:0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['<c>', '<s>', 'INFO', '>', 'My', 'husbands', 'parents', 'are', 'sympathetic']\n"
     ]
    }
   ],
   "source": [
    "s = [word2vec.wv.similar_by_vector(X_train[0,i,:], topn=1)[0][0] for i in range(X_train.shape[1])]\n",
    "print(y_pred)\n",
    "for pred in y_pred:\n",
    "    print(word2vec.wv.similar_by_vector(pred, topn=1)[0][0])\n",
    "    s.append(word2vec.wv.similar_by_vector(pred, topn=1)[0][0])\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from tqdm import tqdm\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Dense, GRU, TimeDistributed, AveragePooling1D, Flatten\n",
    "    \n",
    "class Comment_GRU(object):\n",
    "    def __init__(self, judgements, comment_corpus, N=4, batch_size=16, epochs=10):    \n",
    "        self.judgements = judgements\n",
    "        self.comment_corpus = comment_corpus\n",
    "        self.w2v = self.build_word2vec()\n",
    "        self.vectorize_corpus()\n",
    "        self.N = N\n",
    "        self.vocab_size = len(self.w2v.wv.vocab)\n",
    "        self.embed_size = 100\n",
    "        self.seed = None\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        \n",
    "        self.model = Sequential()\n",
    "        self.model.add(GRU(units=32, batch_input_shape=(self.batch_size, self.N-1, 100), stateful=True, return_sequences=True))\n",
    "        #self.model.add(TimeDistributed(Dense(1)))\n",
    "        #self.model.add(AveragePooling1D())\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(100))\n",
    "        self.model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            print('Epoch: {}'.format(epoch+1))\n",
    "            Xc,yc = self.build_dataset() \n",
    "            X = np.concatenate(list(filter(lambda vals: True if vals.shape[0]>0 else False, Xc.values())),axis=0)\n",
    "            y = np.concatenate(list(filter(lambda vals: True if vals.shape[0]>0 else False, yc.values())),axis=0)\n",
    "            for i in range(int(X.shape[0]/self.batch_size)):\n",
    "                self.model.train_on_batch(X[self.batch_size*i:self.batch_size*(i+1),:,:], y[self.batch_size*i:self.batch_size*(i+1),:])\n",
    "    \n",
    "    def apply_batch_windowing(self, c):\n",
    "        num_subsequences = (c.shape[0]-self.N)+1\n",
    "        start_row = 0 if num_subsequences > self.batch_size else self.batch_size - num_subsequences\n",
    "        windowed_c = np.zeros((self.batch_size, self.N-1, 100))\n",
    "        for i in range(start_row,self.batch_size):\n",
    "            windowed_c[i,:,:] = c[i:i+self.N-1,:]\n",
    "        \n",
    "        return(windowed_c)\n",
    "    \n",
    "    def commentMatrix_to_commentSentence(self, comment_mat):\n",
    "        comment_wordVecs = [comment_mat[0,i,:] for i in range(comment_mat.shape[1]-1)]\n",
    "        for subsequence_ind in range(comment_mat.shape[0]):\n",
    "            comment_wordVecs.append(comment_mat[subsequence_ind,-1,:])\n",
    "        comment_words = [self.w2v.wv.similar_by_vector(wordVec, topn=1)[0][0] for wordVec in comment_wordVecs]\n",
    "        print(comment_words)\n",
    "            \n",
    "    \n",
    "    def generate_comment(self, judgement, max_len):\n",
    "        seed = self.apply_batch_windowing(self.comment_corpus[judgement][0])\n",
    "        comment = None\n",
    "        for i in range(max_len):\n",
    "            self.commentMatrix_to_commentSentence(seed)\n",
    "            #print(seed.shape)\n",
    "            next_subsequence = self.model.predict(seed)\n",
    "            print(next_subsequence.shape)\n",
    "            #print(next_word.shape)\n",
    "            if comment is None:\n",
    "                comment = next_subsequence[1:,:].reshape((1,self.N-1,100))\n",
    "            else:\n",
    "                comment = np.concatenate((comment,next_subsequence[1:,:].reshape((1,self.N-1,100))), axis=0)\n",
    "                #print(comment.shape)\n",
    "            seed = np.concatenate((seed[1:,:,:].reshape((self.batch_size-1,self.N-1,100)),comment[-1,:,:].reshape((1,self.N-1,100))), axis=0).reshape(self.batch_size, self.N-1, 100)\n",
    "            \n",
    "        self.commentMatrix_to_commentSentence(comment)\n",
    "            \n",
    "    # TO DO: Set p to comment upvote score to change sampling distribution with respect to comment popularity.\n",
    "    #def build_batch(self, p=None):\n",
    "        \n",
    "        \n",
    "    def build_dataset(self):\n",
    "        # Use np.random.permutation to create a new ordering of comments for each judgement category. \n",
    "        # self.comment_corpus.values() gives the comments for each category, i.e. each element of the list \n",
    "        # returned by .values() is the list of comments for a particular category, and using len gives the \n",
    "        # number of comments for each category. The function np.arrange creates the default ordering \n",
    "        # (0,1,...len(vals)-1), and np.random.permutation gives a new permuted ordering.\n",
    "        shuffled_comment_inds = list(map(lambda vals: np.random.permutation(np.arange(len(vals))), self.comment_corpus.values()))\n",
    "        \n",
    "        # Zip the new comment orderings back to the judgement category labels.\n",
    "        category_comment_dict = dict(zip(self.comment_corpus.keys(), shuffled_comment_inds))\n",
    "        \n",
    "        X = {}\n",
    "        y = {}\n",
    "        for category_name, category_comment_inds in category_comment_dict.items():\n",
    "            X[category_name] = []\n",
    "            y[category_name] = []\n",
    "            for comment_ind in category_comment_inds:\n",
    "                num_subsequences = self.comment_corpus[category_name][comment_ind].shape[0]-self.N\n",
    "                for i in range(num_subsequences):\n",
    "                    X[category_name].append(self.comment_corpus[category_name][comment_ind][i:i+self.N-1,:])\n",
    "                    y[category_name].append(self.comment_corpus[category_name][comment_ind][i+self.N,:])\n",
    "            X[category_name] = np.array(X[category_name])\n",
    "            y[category_name] = np.array(y[category_name])\n",
    "        return(X,y)\n",
    "    \n",
    "    def build_word2vec(self):\n",
    "        all_comments = []\n",
    "        all_words = []\n",
    "        category_inds = np.arange(len(self.judgements))\n",
    "        for category_ind in category_inds:\n",
    "            for comment_ind in np.arange(len(self.comment_corpus[self.judgements[category_ind]])):\n",
    "                all_comments.append(self.comment_corpus[self.judgements[category_ind]][comment_ind])\n",
    "                #for token in self.comment_corpus[self.judgements[category_ind]][comment_ind]:\n",
    "                #    all_words.append(token)\n",
    "\n",
    "        return(Word2Vec(all_comments, min_count=1))\n",
    "        \n",
    "    def vectorize_corpus(self):\n",
    "        for category_ind in np.arange(len(self.judgements)):\n",
    "            comment_inds = np.arange(len(self.comment_corpus[self.judgements[category_ind]]))\n",
    "            \n",
    "            for comment_ind in comment_inds:\n",
    "                token_inds = np.arange(len(self.comment_corpus[self.judgements[category_ind]][comment_ind]))\n",
    "                \n",
    "                for token_ind in token_inds:\n",
    "                    self.comment_corpus[self.judgements[category_ind]][comment_ind][token_ind] = self.w2v.wv[self.comment_corpus[self.judgements[category_ind]][comment_ind][token_ind]]\n",
    "                \n",
    "                self.comment_corpus[self.judgements[category_ind]][comment_ind] = np.array(self.comment_corpus[self.judgements[category_ind]][comment_ind])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'copy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-bee9dc62f117>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcc_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mc_gru\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mComment_GRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjudgement_categories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcc_copy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'copy' is not defined"
     ]
    }
   ],
   "source": [
    "cc_copy = copy.deepcopy(cc)\n",
    "c_gru = Comment_GRU(judgement_categories, cc_copy, N=32, batch_size=2, epochs=2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_gru.generate_comment('YTA', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Subreddit_Corpus:\n",
    "    def __init__(self, subreddit=None, retrieval_limit=None, bfs_depth=3, judgement_categories=None):\n",
    "        self.bfs_depth = bfs_depth\n",
    "        self.judgement_categories = judgement_categories\n",
    "        self.subreddit = subreddit\n",
    "        self.corpus = []\n",
    "        self.submissions = []\n",
    "        \n",
    "        for submission in self.subreddit.new(limit=retrieval_limit):\n",
    "            self.submissions.append(Submission_Corpus(submission, bfs_depth=bfs_depth, judgement_categories=judgement_categories))\n",
    "            print(submission.selftext)\n",
    "    \n",
    "    def extract_submission(self, submission):\n",
    "        sub = Submission_Corpus(submission, bfs_depth=self.bfs_depth, judgement_categories=self.judgement_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So for a little backstory I (18 f) met my now ex friend who I'll call Dave (26 m) about seven months ago, everything was fine until his gf (23) of four years broke up with him, he came to me for help and i was there for him.\n",
      "\n",
      " Nothing was unusual until about two weeks after the break up when he asked me a favor. The favor was to masturbate with him, which I politely declined, and nothing more was said about that until a week later when he asked me again,  I politely declined again, but he kept on asking me and begging me. It then went from him asking me that, to him begging me to leave my bf for him, which i kept telling him no.\n",
      "\n",
      "I then told my brother what he was doing and showed him screenshots. My brother and my bf tell me call him so that my brother can confront Dave, I finally give in, I call him and give my brother the phone. My brother confronts him for the harassment, I don't like conflict so go outside and let my brother deal with Dave so i don't know what was said on either end. They argued for about 30 minutes, and all is well for like 2 hours.\n",
      "\n",
      " Then  Dave's ex dms me a bunch a insults and is threatening me. Then an hour later my bf tells me that in their discord server Dave and his ex are leaking my number and my bf's number and that they are threatening to find our addresses.\n",
      "\n",
      "I do have screenshots if they are needed.\n",
      "\n",
      "AITA?\n",
      "\n",
      "My ex had an accident at the gym last year. I’m not clear on all the details but it resulted on some piece of equipment falling on top of him and shattering his two front teeth. There was no saving the teeth.  A short time after we ended up splitting for unrelated reasons. \n",
      "\n",
      "Immediately after the accident, he had some custom made temporary snap on veneers made for a couple hundred dollars and they look really really great. They look identical to his previous teeth. They are really great quality and intended to last 3-4 years which is enough for him to save up for real veneers. \n",
      "\n",
      "\n",
      "As of recently we have begun to reconnect and I asked about his teeth. He mentioned  he didn’t wear them because he doesn’t like the lisp they give him and because “it’s an entire mouthpiece.” \n",
      "I asked what he did instead and he mentioned he did nothing. He got used to not having his two front teeth.   I mentioned to him that having Invisalign I could understand how it feels to have a foreign object in your mouth but that after the adjustment period you don’t even notice it. And the lisp goes away. He mentioned he’s not budging and not willing to put his veneers on. I didn’t want to argue or seem shallow so I let it go. \n",
      "\n",
      "We’ve  been wanting to make plans but I cannot get over the missing teeth thing. I know I’m being shallow but it’s just. So. Obvious. My ex is an incredibly handsome guy but without the two front teeth he looks like a meth head. He’s 28! Extremely young. Of course he looks crazy without two front teeth. \n",
      "\n",
      "WIBTA for telling him he should Atleast *try* to wear the veneers for longer than 10 seconds otherwise I won’t get back with him?? \n",
      "\n",
      "TLDR: my ex is missing 2 front teeth and has some really nice snap on veneers for the time but refuses to wear them. WIBTA for choosing to walk instead?\n",
      " \n",
      "Our family do KK for christmas with myself, 2 siblings and our 3 partners. We all get presents for my mother and her partner and they get presents for all of us. We normally do all of our presents to eachother and from within the couples as a family watching each other but Our mother is going away over christmas so we are doing family chirstmas on the 17th with our mum cooking dinner and having us all over and with our presents to them and vice versa being done then. But i am still seeing my siblings and partners on christmas day so we were going to do our KK then instead of with our mother and her partner. My youngest brother and his partner think we should include them and do it with them watching as they think she will want to be included in the moment, but as they are not a part of the KK i dont see why they need to be there, when we could instead have presents to open on christmas day.\n",
      "So AITA for wanting to open presents on christmas day.\n",
      "I am ony my senior year of university. From the very beginning I wanted to leave my university and pursue something else but my mom didn't want me to do it because I choose my department but in my defense I was so unstable and I had only two options and the other one definitely wasn't for me. The day I started university, I became so regretful and whole year I said to my mom that I wanna quit. She prevented me to do that. However, for a long time I am dealing with depression and anxiety and it got worse over the years. Also, my university makes me so unhappy 'cause this is not I want to do. What I wanna do isn't related to what I study anyway. So, over the years, I gave up everything. I couldn't study for my classes and I failed them more then once. Now, I have to take a victory lap. I talked to my mother about leaving and she got angry at me. I said it makes me unhappy. I cried more than once. I became sick. She knows it but doesn't accept that I am getting worse. I started to not attending my classes but she thinks I do. I just can't do it. I really can't. So aita?\n",
      "So i'm in second period english and the teacher leaves the room saying she'll be back in ten minutes. Naturally being 9th graders we go batshit. About five minutes in a guy gets decked. He's down for about 2 seconds. \n",
      "\n",
      "\n",
      "Backstory: The guy who decked the one dude (Imma call him J) accidentialy squirts Germ-X in one guy's (K) eye. K then comes in with a hook to the head. The teacher comes in and K snitches,saying he had done nothing and that J beat him to near death. The teacher asks me if that is true. I then say I was in the bathroom because I didn't want to get into anything. J then got suspended and I went home with a guilty conscience.\n",
      "\n",
      "\n",
      "AITA?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SS = Subreddit_Corpus(subreddit=subreddit, retrieval_limit=5, judgement_categories=judgement_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
