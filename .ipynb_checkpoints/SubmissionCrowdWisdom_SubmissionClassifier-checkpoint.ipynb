{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Crowd Wisdom\n",
    "### Train A Model To Classify Submissions Using The Judgements Passed By Commenters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "from submission_corpus import SubmissionCorpus\n",
    "from subreddit_corpus import SubredditCorpus\n",
    "from ngram_classifier import NgramJudgementClassifier\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Find A Judgemental Subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_name = 'AmITheAsshole'\n",
    "judgement_categories = ['YTA', 'NTA', 'ESH', 'NAH', 'INFO']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Use Reddit API To Load Subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id = '71ZX5Cupn2Ohpg'\n",
    "client_secret = 'nzCz5_WlQM4LbJxX-t_3m-tPgZw'\n",
    "\n",
    "reddit = praw.Reddit(user_agent='Comment Extraction',client_id=client_id, client_secret=client_secret)\n",
    "subreddit = reddit.subreddit(subreddit_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Generate Corpus Of Submissions To Selected Subreddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if submission corpora were already created \n",
    "# (to save the time of creating them again!)\n",
    "filenames = [category+'.txt' for category in judgement_categories]\n",
    "source_already_exists = any([True if filename not in os.listdir() else False for filename in filenames])\n",
    "\n",
    "# If the submission corpora are not in the current directory, build corpora.\n",
    "if not source_already_exists:\n",
    "    sc = SubredditCorpus(subreddit, retrieval_limit=5000, bfs_depth=1, judgement_categories=judgement_categories)\n",
    "    labeled_submissions = sc.get_subredditCorpus()\n",
    "    submission_text = [tup[1] for tup in labeled_submissions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Pick Hyperparameters.\n",
    "  \n",
    "As the number of judgement categories and the vocabulary increases, the smoothing constant should be reduced, otherwise the probability of a 0 frequency word/N-gram will become closer to the probability of a high frequency word/N-gram.\n",
    "  \n",
    "As N increases, the number of unique N-grams usually (though not always) increases. This increase will result in a larger vocabulary, and a larger number of 0frequency N-grams that must be smoothed.  \n",
    "  \n",
    "If you would like to evaluate model performance, you can set a train/test split using train_prop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=1,\n",
    "smoothing_constant = 0.001\n",
    "train_prop = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Build The Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = NgramJudgementClassifier(filenames, N=1,\n",
    "                               smoothing_constant=0.001,\n",
    "                               train_prop=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4a: Evaluate The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf.run_splitTest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Pick/Write A Submission To Classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "submission_1 = \"I'm secretly obsessed with cheese. I'm considering becoming overtly obsessed with cheese. I want to rid the earth of those who do not like cheese; excusing those with dietary preferences/restrictions against dairy. WIBTA if I were to start my dairy fueled conquest of the food pyramid?\"\n",
    "submission_2 = \"I want to help my brother with his anxiety, but I'm not sure what to do. I don't want to make things worse, but I also feel bad if I don't do anything. WIBTA if I try my best to help him (even though I'm not a professional)?\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NTA'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "judgement_categories[clf.predict(submission1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
